{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把Pytorch当做Numpy用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个numpy ndarray\n",
    "numpy_tensor=np.random.randn(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用**两种方式**将numpy的ndarray转换为torch的tensor\n",
    "- `torch.Tensor(ndarray)`\n",
    "- `torch.from_numpy(ndarray)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5297, -0.8408,  0.2289],\n",
      "        [-0.1271, -0.3156, -1.1515]])\n",
      "tensor([[ 0.5297, -0.8408,  0.2289],\n",
      "        [-0.1271, -0.3156, -1.1515]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pytorch_tensor1=torch.Tensor(numpy_tensor)\n",
    "pytorch_tensor2=torch.from_numpy(numpy_tensor)\n",
    "print(pytorch_tensor1)\n",
    "print(pytorch_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以使用**两种方式**将pytorch tensor转换为numpy ndarray.\n",
    "- `pytorch_tensor.numpy()`\n",
    "- `pytorch_tensor.cpu().numpy()`\n",
    "\n",
    "要注意 GPU 上的 Tensor 不能直接转换为 NumPy ndarray，需要使用.cpu()先将 GPU 上的 Tensor 转到 CPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5297042  -0.8408229   0.22885658]\n",
      " [-0.12708993 -0.3156194  -1.1515012 ]]\n"
     ]
    }
   ],
   "source": [
    "# 如果pytorch tensor在cpu上\n",
    "numpy_array=pytorch_tensor1.numpy()\n",
    "# 如果pytorch tensor在gpu上\n",
    "numpy_array2=pytorch_tensor1.cpu().numpy()\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Tensor使用GPU加速**\n",
    "\n",
    "我们可以使用**两种方式**将Tensor放到GPU上\n",
    "- 第一种方式是定义cuda数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5909, -1.0085,  0.4924],\n",
      "        [-0.3589,  1.1792,  1.1899]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dtype=torch.cuda.FloatTensor\n",
    "gpu_tensor=torch.randn(2,3).type(dtype)\n",
    "print(gpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二种方式更简单, `tensor.cuda()`, 直接将tensor放到GPU上,类型跟之前的保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9175, -1.6672,  1.3201],\n",
      "        [ 1.0196,  0.6141, -0.5339]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpu_tensor = torch.randn(2,3).cuda(0) # 将 tensor 放到第一个 GPU 上\n",
    "#gpu_tensor = torch.randn(10, 20).cuda(1) # 将 tensor 放到第二个 GPU 上, 因为我们只有一个GPU,所以我们注释掉这行代码\n",
    "print(gpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch 将tensor放回CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9175, -1.6672,  1.3201],\n",
      "        [ 1.0196,  0.6141, -0.5339]])\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor=gpu_tensor.cpu()\n",
    "print(cpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们也能访问到Tensor的一些属性**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的大小: `tensor.shape`, `tensor.size()`,注意`shape`后边没有括号,因为`shape`是`__init__`中的属性."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.shape)\n",
    "print(pytorch_tensor1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的数据类型: `tensor.type()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的维度: `tensor.dim()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的所有元素的个数: `tensor.numel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "创建一个类型是float64, 大小是3\\*2,随机初始化的tensor,将其转化为numpy的ndarray,输出其数据类型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7166,  0.0612],\n",
      "        [-0.9271,  0.4692],\n",
      "        [ 0.0770, -1.2780]], dtype=torch.float64)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "mytensor=torch.randn(3,2).type(torch.DoubleTensor)\n",
    "myarray=mytensor.numpy()\n",
    "print(mytensor)\n",
    "print(myarray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小结\n",
    "Pytorch tensor的属性或方法:\n",
    "- `tensor.numpy()`\n",
    "- `tensor.cpu()`\n",
    "- `tensor.shape`\n",
    "- `tensor.size()`\n",
    "- `tensor.dim()`\n",
    "- `tensor.numel()`\n",
    "- `tensor.type()`\n",
    "- `tensor.cuda()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor的操作\n",
    "Tensor 操作中的 api 和 NumPy 非常相似，如果你熟悉 NumPy 中的操作，那么 tensor 基本是一致的，下面我们来列举其中的一些操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.ones()`生成全`1`tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tensor.type()`得到tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换tensor数据类型为整形: `tensor.long()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "x=x.long()\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将整形tensor转换为float类型: `tensor.float()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x=x.float()\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 沿着行取最大值: `torch.max(tensor, dim=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6204, -0.4077, -1.3994],\n",
      "        [-0.8982,  0.4406, -1.8149],\n",
      "        [-0.8666,  1.0114, -0.7348],\n",
      "        [ 2.0932, -2.4719, -0.3610]])\n",
      "tensor([1.6204, 0.4406, 1.0114, 2.0932]) tensor([0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,3)\n",
    "print(x)\n",
    "max_value, max_idx=torch.max(x, dim=-1)\n",
    "print(max_value, max_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 沿着行对`x`求和: `torch.sum(tensor, dim=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1867, -2.2725, -0.5900, -0.7398])\n"
     ]
    }
   ],
   "source": [
    "sum_x=torch.sum(x,dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 增加维度或者减少维度: `tensor.unsqueeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x=x.unsqueeze(0) #在第一维度增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x=x.unsqueeze(1) #在第二维度增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x=x.squeeze(0) #减少第一个维度\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x=x.squeeze() #将tensor中所有1维都删掉\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用`permute`和`transpose`进行维度交换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([4, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "print(x.shape)\n",
    "\n",
    "x=x.permute(1,0,2) #将第0维和第1维交换\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x=x.transpose(0,2) #将第0维和第2维交换\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用`view`对tensor进行reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([12, 5])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "print(x.shape)\n",
    "\n",
    "x=x.view(-1,5)\n",
    "print(x.shape)\n",
    "\n",
    "x=x.view(3,20)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 两个tensor求和: `torch.add(tensor1,tensor2)`或者`tensor1+tensor2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4661,  0.0368, -3.1299, -0.4008],\n",
      "        [ 1.9232, -0.9474,  1.1776,  3.5262],\n",
      "        [-0.3276,  1.3257,  0.6753, -0.8982]])\n",
      "tensor([[-0.4661,  0.0368, -3.1299, -0.4008],\n",
      "        [ 1.9232, -0.9474,  1.1776,  3.5262],\n",
      "        [-0.3276,  1.3257,  0.6753, -0.8982]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4)\n",
    "y=torch.randn(3,4)\n",
    "z1=torch.add(x,y)\n",
    "z2=x+y\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch大多数操作支持inplace原地操作,也就是直接对tensor进行操作而不需要开辟内存空间,方式非常简单,一般是在操作的符号后面加`_`,比如:\n",
    "- `unsqueeze_(dim)`进行inplace操作:`unsqueeze_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(3,3)\n",
    "print(x.shape)\n",
    "#unsqueeze进行\n",
    "x.unsqueeze_(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `transpose_(dim1,dim2)`进行inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x.transpose_(1,0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `add_(tensor)`进行inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(3,3)\n",
    "y=torch.ones(3,3)\n",
    "print(x)\n",
    "\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小练习\n",
    "创建一个float32, 4\\*4的全为1的矩阵, 将矩阵中间2\\*2的矩阵,全部修改为2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 2., 2., 1.],\n",
      "        [1., 2., 2., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(4,4).float()\n",
    "x[1:3,1:3]=2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小结\n",
    "Pytorch tensor或torch的方法:\n",
    "- `torch.ones(shape)`\n",
    "- `tensor.long()`\n",
    "- `tensor.float()`\n",
    "- `torch.max(tensor,dim)`\n",
    "- `torch.sum(tensor,dim)`\n",
    "- `tensor.unsqueeze(dim).`\n",
    "- `tensor.squeeze(dim)`\n",
    "- `tensor.permute(new_dim)` \n",
    "- `tensor.transpose(dim1,dim2)`\n",
    "- `tensor.view(new_shape)`\n",
    "- `tensor.add(tensor1,tensor2)`\n",
    "- `tensor1+ tensor2`\n",
    "- `tensor.unsqueeze_(dim)`\n",
    "- `tensor.transpose_(dim)`\n",
    "- `tensor_1.add_(tensor_2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. Variable\n",
    "tensor 是 PyTorch 中的完美组件，但是构建神经网络还远远不够，我们需要能够构建计算图的 tensor，这就是 **Variable**。\n",
    "\n",
    "Variable 是对 tensor 的封装，操作和 tensor 是一样的，但是每个 Variabel都有三个属性:\n",
    "- Variable 中的 tensor本身`.data`，\n",
    "- 对应 tensor 的梯度`.grad`\n",
    "- Variable 是通过什么方式得到的`.grad_fn`\n",
    "\n",
    "注意: Variable(tensor)返回的依然是tensor类型.换句话说,tensor本身就带有`.data`,`.grad`,`grad_fn`三个属性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将tensor变成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor=torch.randn(2,3)\n",
    "y_tensor=torch.randn(2,3)\n",
    "\n",
    "x=Variable(x_tensor, requires_grad=True) #默认Variable是不需要求梯度的, 所以我们需要用这个方式申明需要对其进行求梯度\n",
    "y=Variable(y_tensor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 得到Variable的数值及获得方式: `tensor.data`,`tensor.grad_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5982)\n",
      "<SumBackward0 object at 0x000001CC9270C828>\n",
      "tensor([[-2.1567, -1.9161,  1.4580],\n",
      "        [ 0.5328,  0.1171,  1.3667]])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "z=torch.sum(x+y) #不指定dim就把所有元素相加\n",
    "z1=x+y\n",
    "\n",
    "print(z.data)\n",
    "print(z.grad_fn)\n",
    "print(z1.data)\n",
    "print(type(z1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 得到Variable的梯度: `variable.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1281, -0.2999,  1.1750],\n",
      "        [-1.0195, -0.2167,  1.0767]])\n",
      "tensor([[-2.0285, -1.6163,  0.2830],\n",
      "        [ 1.5523,  0.3337,  0.2900]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#求x和y的梯度\n",
    "z.backward()\n",
    "\n",
    "print(x.data)\n",
    "print(y.data)\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小练习\n",
    "尝试构建一个函数 $y=x^2$,然后求$x=2$的导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4VFX+x/H3mcmkA4EkBEISQggtIr0jioJddO2ADd0Ve1m36Kqr7rq6lrW7Fqyrgti7oigoiLQAkZYAISEVUgghCSkkM+f3R6I/RcoQMjn3znxfz5NHMl4yn0vw4825556jtNYIIYSwD4fpAEIIIQ6PFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQthMkC++aExMjE5OTvbFlxZCCL+0atWqcq11rDfH+qS4k5OTSU9P98WXFkIIv6SUyvP2WBkqEUIIm5HiFkIIm5HiFkIIm5HiFkIIm5HiFkIIm5HiFkIIm5HiFkIIm7FMcdc3unlhUQ4/bC03HUUIIQ7bwqxSXlmSy94mj8/fyzLFHeRQvLA4h5cW55qOIoQQh+3Z77byvx+24XIqn7+XdYrb6eC84Qks3FTKjt31puMIIYTXcspqWJFbwQUjE1EqgIob4IIRiXg0vLuqwHQUIYTw2lvpBTgdivOGJbTL+1mquJNjIhibEs1b6QV4PNp0HCGEOKRGt4f3VhVyQv+udO0Y2i7vaaniBpg6KpGCijqW5uw0HUUIIQ7pm8xSymv2MnVkYru9p+WK++SjutEpzMWbK/JNRxFCiEOauzKfbh1DOa6vVyuytgnLFXeoy8nZQ3vw1YYSKvbsNR1HCCEOqLiyju82l3H+iASCnO1Xp5YrboALRyay1+3hgzVFpqMIIcQBvZNeiNbNEyvakyWLe0D3jgxOjOKtlfloLTcphRDW4/Zo3k4v4JjUGBK7hLfre1uyuAGmjkxkc0kNawoqTUcRQojfWJJdTlFlHRe2403Jn1i2uKcMjic82MlcuUkphLCguSvz6Rzu4qSj4tr9vS1b3JEhQUwZFM8nP26nur7RdBwhhPhZeU0D8zeWcM6wBEKCnO3+/pYtboALRyVS1+jmkx+3m44ihBA/+2B1EY1ubWSYBCxe3EMTo+gX14G5K2W4RAhhDVpr3lyRz7CkKPrGdTCSwdLFrZRi+ugk1hbuZm2h3KQUQpi3NGcnOeV7uGh0T2MZLF3cAGcP60GYy8mc5XLVLYQwb/byfDqFuTh9UHdjGSxf3B1DXZw5OJ6PMoqpkpuUQgiDyqob+HL9Ds4bnkCoq/1vSv7E8sUNcNGYJOoa3XwkT1IKIQx6Z1UBTR7N9NFJRnPYorgHJUQxsEdHZi+XJymFEGZ4PJo5y/MZk9KF3rGRRrN4VdxKqT8qpTYopdYrpd5USrXPorO/cNHonmTtqGZ1/q72fmshhGDRljIKd9UZvSn5k0MWt1KqB3AjMEJrPRBwAlN9HWxfZw6OJzIkiNnL5CalEKL9zV6eT3REMCcf1c10FK+HSoKAMKVUEBAOFPsu0v5FhARx9tAefLpuO5W1styrEKL9bN9dx4KsUi4YmUhwkPkR5kMm0FoXAf8B8oHtwG6t9Vf7HqeUmqmUSldKpZeVlbV9UmD66CT2Nnl4d1WhT76+EELsz1srC3B7NNNGmr0p+RNvhko6A2cBvYB4IEIpdfG+x2mtZ2mtR2itR8TG+mYniAHdOzIsKYo5cpNSCNFOmtwe5q4o4Ni+sSRFt+/yrQfizTX/ZCBXa12mtW4E3gfG+TbWgV00uic55XtkT0ohRLtYkFXKjqp6LjI8BfCXvCnufGCMUipcKaWASUCmb2Md2OmDutMpzCU3KYUQ7WL28nziOoYwqX9X01F+5s0Y93LgXWA1sK7l98zyca4DCnU5OX94Al9u2EFJVb2pGEKIALCtfA/fbS5j2qikdt1T8lC8SqK1vltr3V9rPVBrfYnWusHXwQ7m4jE9cWst65cIIXzq9WV5BDkU00dZZ5gEbPLk5L6SYyI4rm8sc1bks7fJYzqOEMIP1e5t4p30Ak4Z2I2uHdv9mcODsmVxA1w6tmfzgi8bdpiOIoTwQ80L2zVx6dhk01F+w7bFfVzfriR1Cef1pXmmowgh/IzWmteW5tG/WwdGJnc2Hec3bFvcTofi4jFJrNhWQeb2KtNxhBB+ZFXeLjK3V3Hp2GSaJ9NZi22LG+CCEYmEBDl4Ta66hRBt6H9L8+gQGsTvhsabjrJfti7uqPBgzhoSz4drithdJ5ssCCGOXGlVPV+s2875wxMJDw4yHWe/bF3cAJeOTaau0S3rlwgh2sSbK5o3S7hkrPnlWw/E9sU9sEcnhiVF8cayPDweWb9ECNF6jW4Pc1bkcWzfWHrFRJiOc0C2L26Ay8Ylk1u+h8XZ5aajCCFs7KsNJZRUNXCZha+2wU+K+5SB3YiJDOa1H7aZjiKEsLHXlm4joXMYE/tZZ12S/fGL4g4JcjJ9VBILNpWyrXyP6ThCCBvaULyb5bkVXDq2J06H9aYA/pJfFDc0r18S5FC8KlfdQohWeGXJNsKDnVw4wlrrkuyP3xR3146hnDEonnfSC6iql6mBQgjvlVU38HFGMecOS6BTuMt0nEPym+IGuGJ8L/bsdfNOukwNFEJ4b87yfPa6PcwYn2w6ilf8qriPTujEyOTOvPpDLm6ZGiiE8EJDk5vXl+VxfL9YesdGmo7jFb8qboDLx/eioKKOrzNLTEcRQtjApz9up7ymgcvH9zIdxWt+V9wnpcXRIyqMV5bkmo4ihLA4rTUvL8kltWskE/rEmI7jNb8r7iCng0vH9mRZTgUbinebjiOEsLCV23axobiKy8dbcxXAA/G74gaYOjKJMJeTV5dsMx1FCGFhryzJpVOYi3OGJpiOclj8srg7hbs4b3gCH2UUU15jdHtMIYRFFVTU8uWGHUwfnURYsNN0nMPil8UNMGN8MnvdHmYvkw2FhRC/9drSbSiluGSMtdcl2R+/Le7esZFM7BfL68vyqG90m44jhLCQmoYm5q5s3gg4PirMdJzD5rfFDXDlhBTKaxr4KKPIdBQhhIXMXZFPdX0TMyekmI7SKn5d3ON6R5PWvSMvLM6VtbqFEAA0uT28smQbo3p1YXBilOk4reLXxa2UYuaxKWSX1vDd5jLTcYQQFvD5+h0UVdbZ9mob/Ly4AU4f1J3unUKZtSjHdBQhhGFaa2Yt2kpKbAQn9Lf2mtsH4/fF7XI6uGJ8L5bm7GRdoTyQI0QgW5ZTwfqiKq6ckILD4mtuH4zfFzfA1FGJdAgJ4oXFctUtRCB7YXEOMZHBnD20h+koRyQgirtDqItpo5P4bN12CnfVmo4jhDBgS0k1C7JKuXRsMqEuez1ws6+AKG6AGeOSUTTvciGECDwvLs4l1OXgYhs+cLOvgCnu+KgwpgyOZ+6KfHbXyQ45QgSS0up6PlhTxPnDE+kSEWw6zhELmOIG+MOE5h1y3lwhj8ELEUhe+yGPRo+H3x9jnzW3Dyagivuo+E6MT43mlSW5NDTJY/BCBII9DU28sTyPk9LiSI6JMB2nTQRUcQNcfVxvSqoa+HCNPAYvRCB4c0U+lbWNXHVcb9NR2oxXxa2UilJKvauUylJKZSqlxvo6mK8ckxrDwB4dee67HNmXUgg/19Dk5sXFuYxJ6cKwpM6m47QZb6+4nwDmaa37A4OBTN9F8i2lFNdOTCW3fA/z1u8wHUcI4UMfriliR1U9105MNR2lTR2yuJVSHYFjgZcAtNZ7tdaVvg7mSycf1Y2UmAie/S4breWqWwh/5PZonv8uh4E9OtpqP0lveHPFnQKUAa8opdYopV5UStl6hN/pUFx1XArri6pYvKXcdBwhhA98uWEHOeV7uOa4VFvtJ+kNb4o7CBgGPKu1HgrsAW7b9yCl1EylVLpSKr2szPor8Z09NIFuHUN55tts01GEEG1Ma80z32aTEhPBKQO7mY7T5rwp7kKgUGu9vOXzd2ku8l/RWs/SWo/QWo+IjY1ty4w+ERzk4A8TerEsp4LV+btMxxFCtKHvs8tZX1TFVcel4LTxYlIHcsji1lrvAAqUUv1aXpoEbPRpqnYybVQSUeEunv12q+koQog29MzCrcR1DOF3Nl9M6kC8nVVyAzBbKbUWGALc77tI7SciJIjLxiYzf2MJm0uqTccRQrSBNfm7WJqzkysnpBASZO/FpA7Eq+LWWme0DIMM0lr/TmvtN2MLM8YlE+Zy8pxcdQvhF575diudwlxMG5VkOorPBNyTk/vqHBHMtFFJfPRjMfk7ZclXIexs045q5m8s4bJxyUSEBJmO4zMBX9zAzzcwnv1OZpgIYWdPLdhCRLCTK8Ynm47iU1LcQFzHUKaOTOTdVYWy0YIQNpVdWs1n67Zz2bhkosLtv3TrwUhxt7i6ZQGa576TsW4h7OjpBdmEuZz8wca7t3tLirtFfFQY5w1P5O2VhezYXW86jhDiMOSW7+HjH4u5eExPv9go4VCkuH/h2om98WgtV91C2Mx/F2bjcjq4MgCutkGK+1cSu4RzzrAevLkin9IqueoWwg7yd9bywZoiLhrdk9gOIabjtAsp7n1cd3wqTR7NrEU5pqMIIbzwzLfZPy8cFyikuPfRMzqCs4bE88byPMprGkzHEUIcROGuWt5dVci0kYnEdQw1HafdSHHvx3XHp9LQ5OGFxXLVLYSVPfvtVpTCr7Yl84YU9370jo1kyqB4Xl+ax0656hbCkoor63gnvZDzRyQSHxVmOk67kuI+gBsnpVLf6OZ5GesWwpKeWpCNRnPtxMC62gYp7gNK7dqB3w3pwWtLt1FaLTNMhLCS/J21vJNewLRRSSR0Djcdp91JcR/EjZP60OjWPLNQ5nULYSVPLtiC06G47nj/2gTYW1LcB5EcE8F5wxKYszyf4so603GEEMDWshreX13IxWN6BtRMkl+S4j6EGyalotE8vVBWDhTCCp74egshQU6uCcCx7Z9IcR9CQudwpo5M4u2VBbJetxCGbdpRzSdri5kxPpmYyMB4SnJ/pLi9cN3xqTgciicXbDEdRYiA9tj8zUQEBzEzQNYkORApbi906xTKJWN68v7qQnLKakzHESIgrS/azbwNO/j9Mb3oHAArAB6MFLeXrpnYm5AgJ49/LVfdQpjw6PzNdApz8fsJvUxHMU6K20sxkSHMGJ/MJ2uLydxeZTqOEAFlVd4uFmSVMvPYFDqGukzHMU6K+zBcdWwKHUKCePjLTaajCBEwtNY8+EUWMZEhXO7ne0l6S4r7MESFB3PNxFQWZJWyPGen6ThCBISFm0pZsa2Cmyb3ITzYf3duPxxS3Idpxrhk4jqG8MC8LLTWpuMI4dfcHs2DX2wiOTqcqSMTTcexDCnuwxQW7OSPk/uyJr+SrzaWmI4jhF/7cE0Rm0qq+fPJ/XA5pa5+In8SrXDe8AR6x0bw0Lwsmtwe03GE8Ev1jW4enb+Zo3t04rSB3U3HsRQp7lYIcjr4y8n92Vq2h/dWF5qOI4RfemNZHkWVddx2an8cDmU6jqVIcbfSyUfFMTQpisfmb6G+0W06jhB+paq+kacXZjOhTwzjU2NMx7EcKe5WUkpx6yn92VFVz6s/bDMdRwi/Muu7HCprG7n1lP6mo1iSFPcRGJMSzfH9YnlmYTaVtXtNxxHCL5RW1fPS97lMGRzPwB6dTMexJCnuI3Trqf2paWjiyW9k2Vch2sJ/vtpEk8fDn0/qazqKZUlxH6H+3TpywYhEXlu6TRagEuIIbSjezTurCrlsbDI9oyNMx7EsKe42cMtJfQkJcvDAF1mmowhhW1pr7vssk6gwFzdM6mM6jqVJcbeBrh1Cufb4VL7aWMLSrfIovBCt8U1mKT9s3cnNk/vSKUwWkjoYKe428vtjehHfKZR/fbYRj0cehRficDS6Pdz/eSYpsRFMH51kOo7leV3cSimnUmqNUupTXwayq1CXk1tP7c+G4ireX1NkOo4QtjJ7WR455Xu447QB8mi7Fw7nT+gmINNXQfzBmYPjGZIYxcNfZlG7t8l0HCGsbfZsSE5GOxycdPoY/lKezgn9u5pOZQteFbdSKgE4HXjRt3HsTSnF388YQElVA7MW5ZiOI4R1zZ4NM2dCXh5Ka+J3l3LNnAdRc+aYTmYL3l5xPw78FZAVlQ5heM8unD6oO89/l8P23XWm4whhTXfcAbW1v3rJUVfX/Lo4pEMWt1LqDKBUa73qEMfNVEqlK6XSy8rK2iygHd12Sn88WvPvz2V6oBD7lZ9/eK+LX/Hmins8cKZSahswFzhBKfXGvgdprWdprUdorUfExsa2cUx7SewSzlXH9ebjH4tZJjvlCPFbSQeYOXKg18WvHLK4tdZ/01onaK2TganAAq31xT5PZnPXHNebHlFh3PPxBlmzW4h97P3nvdS7Qn79Yng43HefmUA2I/NufCQs2Mnfz0gja0c1byzLMx1HCEuZlTCGv558PfXxCaAU9OwJs2bBRReZjmYLh1XcWutvtdZn+CqMvzn5qDgm9InhkfmbKa9pMB1HCEsoqqzj6YXZNF44jdCiAvB4YNs2Ke3DIFfcPqSU4u4pR1G3183D8zaZjiOEJdz/WfPjIHecPsBwEvuS4vax1K6R/P6YXryVXkBGQaXpOEIYtSS7nM/Wbee6iakkdA43Hce2pLjbwQ2T+tC1Qwh3f7Re1jERAavR7eHujzeQ1CWcK49NMR3H1qS420FkSBC3nzaAHwt3M3dlgek4QhjxypJcsktruOuMNEJdTtNxbE2Ku52cNSSeMSldeOCLTMqq5UalCCyFu2p5bP4WJg/oyqQBsh7JkZLibidKKe47+2jqGz3867ONpuMI0W601tz10QaUgn+cNRCllOlItifF3Y56x0ZyzcTefJRRzKLNgb0sgAgc89bvYEFWKbec2JceUWGm4/gFKe52ds3E3qTERHDnh+upb3SbjiOET1XXN3LPJxtI696RGeOSTcfxG1Lc7SzU5eRfZw8kv6KWpxfIzvDCvz3y1WZKqxv49zlHEyQbJLQZ+ZM0YFzvGM4Z1oPnF21lc0m16ThC+MSPBZX8b+k2Lh3Tk8GJUabj+BUpbkPuOG0AESFB3PHBOpnbLfxOk9vD395fR9cOIfzp5H6m4/gdKW5DoiNDuP20Aazctos3V8oaxMK/vLwkl43bq7hnylF0DJUd29uaFLdB5w9PYFzvaP79eRZFlbJbjvAPOWU1PPLVZiYPiOOUgd1Mx/FLUtwGKaV44JxBuD2av72/Dq1lyETYm9uj+eu7awkJcnD/2TJn21ekuA1Lig7n1lP6sWhzGe+uKjQdR4gj8trSbaTn7eKuKUfRtWOo6Th+S4rbAi4dm8yo5C7c++lGSqrqTccRolXydu7hoXmbmNgvlnOH9TAdx69JcVuAw6F48LxBNDR5uOMDGTIR9uPxaG59by1BDsW/zzlahkh8TIrbInrFRPCXk/vxdWYpH2UUm44jxGGZvSKfZTkV3HH6ALp3ksfafU2K20IuH9+LYUlR3PPJBkqrZchE2EPhrloe+DyTCX1iuHBkouk4AUGK20KcDsVD5w2mdq+b22WWibABj0fzl3fWAsgQSTuS4raY1K6R/LVlyEQ2XRBW99L3uSzN2cldU9JkK7J2JMVtQVeM78X41Gju/XQj28r3mI4jxH5lbq/i4S83cVJaHBeMkCGS9iTFbUEOh+I/5w8myKG4+a0Mmtwe05GE+JX6Rjd/fCuDjmEuGSIxQIrborp3CuO+s48mo6CS/y7cajqOEL/yyFebyNpRzcPnDSI6MsR0nIAjxW1hUwbH87sh8Ty5YAtr8neZjiMEAD9kl/PC4lwuHpPE8f1l/0gTpLgt7h9nDSSuQwi3vP0jtXubTMcRAW53bSN/eudHUmIiuOO0NNNxApYUt8V1CnPxyAVD2LZzD//8RDYZFuZorbn9w3WUVTfw2IVDCAt2mo4UsKS4bWBs72iuOa43c1cW8FFGkek4IkDNWZHPZ2u3c8tJfWVHG8OkuG3ilhP7MqJnZ25/fx05ZTWm44gAs7G4in98spFj+8Zy9bG9TccJeFLcNhHkdPDktKG4ghxcN2eN7BAv2k1NQxPXz1lNVJiLRy8YjMMhU/9Mk+K2kfioMB69YDCZ26v412cy3i18T2vNnR+sY9vOPTw5bSgxMvXPEqS4beaE/nHMPDaFN5Y1jzcK4UvvpBfyYUYxN0/uy5iUaNNxRAspbhv6y8n9GJIYxW3vrSVvpzwSL3xjc0k1d328nnG9o7nu+FTTccQvSHHbkMvp4OnpQ1EKrnljNXV7ZbxbtK3q+kaufmMVkSFBPD51CE4Z17YUKW6bSugczuNTh5C5o4q/vb9WloAVbcbj0dzy9o/k7azl6enD6NpB9o60mkMWt1IqUSm1UCmVqZTaoJS6qT2CiUM7oX8ct0zuy4cZxbyyZJvpOMJPPL0wm/kbS7jz9AEyrm1R3lxxNwF/0loPAMYA1yml5FlXi7ju+FROSovjvs8zWbp1p+k4wua+ySzhsa83c87QHswYl2w6jjiAQxa31nq71np1y6+rgUxAtnC2CIdD8cgFg0mODuf6OaspqqwzHUnYVE5ZDTfPzSCte0ful6VaLe2wxriVUsnAUGC5L8KI1ukQ6mLWpSNoaPJw9eur5OEccdhqGpq46vVVBDkVz18ynFCXrENiZV4Xt1IqEngPuFlrXbWffz9TKZWulEovKytry4zCC71jI3nswiGsK9ot+1WKw+LxaP70dgZby2r47/RhsgWZDXhV3EopF82lPVtr/f7+jtFaz9Jaj9Baj4iNjW3LjMJLJ6bFccuJfXl/TRFPL8g2HUfYxIPzsvhyQwl3np7GuNQY03GEF4IOdYBqHuh6CcjUWj/q+0jiSNxwQirbyvfwyPzNJEWHc9YQuR0hDuzNFfk8vyiHS8b05PLxyabjCC95c8U9HrgEOEEpldHycZqPc4lWUkrx73OPZlSvLvzl3bWsyqswHUlY1OItZdz54Xom9ovl7ilpcjPSRryZVfK91lpprQdprYe0fHzeHuFE64QEOXn+4uH0iArjytdWyWPx4jc2l1Rz7Rur6dM1kqemDSXIKc/i2Yl8t/xU54hgXp4xEo/WXP7qSnbXNpqOJCyirLqBy19ZSWiwk5dmjKRDqMt0JHGYpLj9WK+YCJ6/eDgFFbXMfD1dpgkK9jQ08YfX0tm5p4GXLhtBj6gw05FEK0hx+7nRKdH85/zBLM+t4MY319Dk9piOJAxpaHJz9RurWF+0m6emDWNQgmw/ZldS3AHgrCE9uGdKGl9tLOFvMsc7ILk9mlve+pHFW8p58NxBnJgWZzqSOAKHnA4o/MOM8b3YVdvIE99sISrcxe2nDZBZBAFCa82dH67ns3XbufP0AZw3PMF0JHGEpLgDyM2T+1BZu5cXFufSOSKYayfK4viB4OEvN/HminyuO743f5iQYjqOaANS3AFEKcXdU46isq6Rh+ZtIiosmOmjk0zHEj70wqIcnvl2K9NHJ/Hnk/qZjiPaiBR3gHE4FP85fzDV9U3c8eE6ghyKC0Ymmo4lfODl73O57/NMTh/UnXvPGihDY35Ebk4GIJfTwTMXDePYPrH89b21vLUy33Qk0cZe+j6Xf366kVMHduPxC2XrMX8jxR2gQl1Onr9kOBP7xXLre+uYu0LK21+8uDiHez/dyGlHd+PJaUNxyVORfke+owEs1OXkuYuHc3y/WG57fx1zlkt5292Li3P412eZnH50d56YKqXtr+S7GuBCXU6eu6S5vG//YB2zl+eZjiRa6YVF/1/aj08dIqXtx+Q7KwgJai7vE/p35Y4P1vPMt9nykI6NaK15+Musn29EPiGl7ffkuyuAlvK+eDhnDo7noXmbuPfTTDweKW+ra3J7uO29dfx34VamjUrkyamy0l8gkOmA4mfBQQ4ev3AI0ZHBvLwkl517Gnj4vMEEB0kRWFF9o5sb3lzD/I0l3HhCKn88sa9M+QsQUtziVxwOxV1npBHbIYSH5m1iV20jz140jIgQ+atiJbvrGrnyf+mszKvgH2cexWXjkk1HEu1ILqXEbyiluHZiKg+dO4jvt5Qx/YVllFbVm44lWhTuquXC55eypmAXT00bKqUdgKS4xQFdMDKRWZeMYEtpDWc+vYS1hZWmIwW8ldsqOOvpJRRV1vHKjFGcMSjedCRhgBS3OKjJaXG8d804nA7F+c8t5aOMItORAtbcFflMf2EZncJcfHjdeI7pIzuyByopbnFIA7p35OPrxzM4IYqb5mbw8JdZMuOkHTW5Pdzz8QZue38dY1Ki+eDa8fSOjTQdSxgkxS28Eh0Zwht/GM20UYn8d+FWZr6+it11so+lr+2saeDyV1fy6g/b+P0xvXhlxkg6hcsekYFOilt4LTjIwf1nH809U9L4dlMppz2xmNX5u0zH8ls/bC3n1CcWszy3gofOHcTfz0iTOdoCkOIWh0kpxYzxvXjn6rEoBec/t5Rnv90qQydtqMnt4dH5m7noxeVEhgbxwbXjZOld8StS3KJVhiZ15rMbJ3DKUd14cF4Wl72ygrLqBtOxbG/77jqmv7CcJ7/ZwrnDEvjk+mM4Kr6T6VjCYqS4Rat1CnPx9PSh3H/20azIreDUJxYzb/1207FsSWvNRxlFnPrEYtYX7+axCwfzn/MHy4NPYr+kuMURUUoxfXQSH19/DF07hHD1G6u5dvYqSqvlgR1vFVfW8fv/pXPT3AySoyP49IZjOHuobOgrDkz5YhW4ESNG6PT09Db/usLaGt0eZi3K4YlvthDmcvL3M9I4d1gPWT/jADwezZwV+TzwRRZuj+bPJ/djxrhk2a0mQCmlVmmtR3h1rBS3aGvZpTXc+t5aVuXt4ti+sdwzJY0UmXf8K5t2VHPXR+tZnlvB+NRo/n32IJKiw03HEgZJcQvjPB7N68vyeGheFg1NHi4Z25ObJvUhKjzYdDSjyqobeOzrzcxdkU9kSBB3nD6AC0Ykyk8lQopbWEdZdQOPzt/MWyvz6RDq4sZJfbhkTM+AWyq2vtHNy0tyeWbhVuob3Vw8pvl/ZJ0jAvt/ZOL/SXELy8naUcV9n2WyeEs5vWIiuOGEVKZGRgxvAAAHOUlEQVQMjvf7nVoamtx8sLqIpxZkU1RZx+QBcfzttP7yyLr4DSluYUlaa77dXMaDX2SRtaOahM5hXHVcb84fnkCoy2k6Xpuq3dvEmysKeGFRDjuq6jm6RyduO7U/41NlYSixf1LcwtK01izIKuXphdmsya8kJjKEP0zoxdSRibYfA99Z08Cc5fm8vCSXXbWNjEnpwrUTU5nQJ0bGscVBSXELW9Basyyngme+zWbxlnKCgxycOrAbF45IZExKNA6bTItzezTfZ5fz1sp85m8sodGtmdS/K9ce35vhPbuYjids4nCKWx7LEsYopRjbO5qxvaPZWFzFWyvz+WBNER9lFJPUJZwLRiQwZXA8PaMjTEfdr61lNXycUcy7qwopqqyjc7iLS8cmM3VkIn3iOpiOJ/yYV1fcSqlTgCcAJ/Ci1vqBgx0vV9yiteob3cxbv4O5K/NZllMBQJ+ukUwaEMeJaV0ZktjZ2AMqTW4Pq/J28XVmCV9nlpJbvgeACX1iuHBkIiemxRES5F9j9aL9tOlQiVLKCWwGTgQKgZXANK31xgP9Hilu0RYKKmqZv7GErzNLWJFbQZNHEx0RzOiULgxJjGJoUmcGxnciLNg3ZbmnoYl1RbtZk19JRsEuludWUFnbiMupGJMSzYlpcUwaEEePqDCfvL8ILG09VDIKyNZa57R88bnAWcABi1uItpDYJZwrjunFFcf0YnddI99tLmNBZgmr8nfx+bodADgdiv7dOtA3rgOJXcJJ7BxGYpdwkrqE0yUimJAgxwFvCmqtaWjyUF7TQEFFHQUVtRTsqqWgopasHdVsLqnmp9Vqe0aHc0L/rkweEMeEPjF0CJXNDIQ53hR3D6DgF58XAqN9E0eI/esU5uLMwfGcObh5c9zymgYy8ivJKGj+WJFbwYcZRez7A6RDQXhwEGHBTsKDnWgNtXvd1O1toq7Rzb7LiDsUdO8URkpsBCelxTE0qTODE6PoIg/KCAvxprj3d7nym/EVpdRMYCZAUlLSEcYS4uBiIkOYnBbH5LS4n1/b2+ShuLKOgl215FfUUlnbSN1eN7V73dTubaJ2rxulIDzYSZgrqPmfwU66RAST2Ln5Kr17VKjfPxQk7M+b4i4Efrn9RgJQvO9BWutZwCxoHuNuk3RCHIbgIAfJMREkx1hzFooQbcWbS4uVQB+lVC+lVDAwFfjYt7GEEEIcyCGvuLXWTUqp64EvaZ4O+LLWeoPPkwkhhNgvrx7A0Vp/Dnzu4yxCCCG8IHdhhBDCZqS4hRDCZqS4hRDCZqS4hRDCZqS4hRDCZnyyHrdSqgzIa+VvjwHK2zCOSf5yLv5yHiDnYkX+ch5wZOfSU2sd682BPinuI6GUSvd2hSyr85dz8ZfzADkXK/KX84D2OxcZKhFCCJuR4hZCCJuxYnHPMh2gDfnLufjLeYCcixX5y3lAO52L5ca4hRBCHJwVr7iFEEIchCWLWyl1r1JqrVIqQyn1lVIq3nSm1lBKPayUymo5lw+UUlGmM7WWUup8pdQGpZRHKWW7GQBKqVOUUpuUUtlKqdtM5zkSSqmXlVKlSqn1prMcCaVUolJqoVIqs+Xv1k2mM7WWUipUKbVCKfVjy7n8w6fvZ8WhEqVUR611VcuvbwTStNZXG4512JRSJwELWpbGfRBAa32r4VitopQaAHiA54E/a61tsxt0aza8tjKl1LFADfCa1nqg6TytpZTqDnTXWq9WSnUAVgG/s+P3RTVvbBqhta5RSrmA74GbtNbLfPF+lrzi/qm0W0Swn63S7EBr/ZXWuqnl02U07x5kS1rrTK31JtM5WunnDa+11nuBnza8tiWt9SKgwnSOI6W13q61Xt3y62ogk+Y9bm1HN6tp+dTV8uGz3rJkcQMope5TShUAFwF3mc7TBq4AvjAdIkDtb8NrWxaEv1JKJQNDgeVmk7SeUsqplMoASoH5WmufnYux4lZKfa2UWr+fj7MAtNZ3aK0TgdnA9aZyHsqhzqPlmDuAJprPxbK8OReb8mrDa2GGUioSeA+4eZ+ftm1Fa+3WWg+h+SfrUUopnw1jebUDji9orSd7eegc4DPgbh/GabVDnYdS6jLgDGCStuINhV84jO+J3Xi14bVofy3jwe8Bs7XW75vO0xa01pVKqW+BUwCf3EC25FCJUqrPLz49E8gyleVIKKVOAW4FztRa15rOE8Bkw2sLarmh9xKQqbV+1HSeI6GUiv1p1phSKgyYjA97y6qzSt4D+tE8iyEPuFprXWQ21eFTSmUDIcDOlpeW2XF2DIBS6mzgKSAWqAQytNYnm03lPaXUacDj/P+G1/cZjtRqSqk3gYk0r0RXAtyttX7JaKhWUEodAywG1tH83zrA7S173NqKUmoQ8D+a/345gLe11v/02ftZsbiFEEIcmCWHSoQQQhyYFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtjM/wGi0xonU1UbyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=np.arange(-3,3.01,0.1)\n",
    "y=x**2\n",
    "plt.plot(x,y)\n",
    "plt.plot(2,4,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**答案**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "x=Variable(torch.FloatTensor([2]),requires_grad=True)\n",
    "y=x**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
