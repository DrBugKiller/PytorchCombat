{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把Pytorch当做Numpy用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个numpy ndarray\n",
    "numpy_tensor=np.random.randn(10,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用**两种方式**将numpy的ndarray转换为torch的tensor\n",
    "- `torch.Tensor(ndarray)`\n",
    "- `torch.from_numpy(ndarray)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3477,  1.7881,  0.1020, -3.0489,  0.7468,  0.5973,  0.5773, -0.0708,\n",
      "         -1.3510,  0.0036, -0.4196, -1.4115,  0.2081,  1.3612,  1.8832, -2.0351,\n",
      "         -0.8593, -0.6753,  0.5418,  0.1723],\n",
      "        [-0.4780, -0.3307, -0.5252, -0.2710,  0.3715, -1.2678, -0.4747,  0.7486,\n",
      "          0.6462,  0.0216, -1.3910, -0.6312, -0.2180,  0.3948,  0.9092, -0.6908,\n",
      "          0.6315, -0.7504, -1.6323, -2.4337],\n",
      "        [-0.3478,  0.1459,  1.4962,  0.8018,  0.2325, -1.3683, -0.2767, -0.6959,\n",
      "          0.4707, -1.4066, -1.0317, -0.1964,  0.7980, -0.6775, -1.5452,  0.4839,\n",
      "         -0.0455, -1.1354,  1.3209, -3.0151],\n",
      "        [ 1.4615, -1.8403, -1.8994, -1.1997, -0.0858,  1.6973,  1.0535,  0.3474,\n",
      "          1.3348, -1.0051,  0.3828, -0.0168,  0.0653,  1.1355, -0.2066,  0.1851,\n",
      "         -0.8155,  0.0409,  0.7851,  1.7631],\n",
      "        [-0.5739, -0.8242,  0.1789,  0.7699, -2.2492,  1.8560,  0.9774,  0.5689,\n",
      "         -0.2137, -0.6988, -0.1610, -1.2823, -0.8182,  1.5304,  0.6233,  0.4378,\n",
      "          0.3209,  0.2028, -0.4783,  2.6814],\n",
      "        [ 0.1592, -0.8178,  0.0085,  1.1814,  0.1288, -0.1295, -1.0593, -1.0653,\n",
      "         -0.6312, -1.1314, -0.1144, -0.9894,  0.7163, -0.0964,  0.1577, -1.4139,\n",
      "          0.1347, -1.7582, -3.4288,  0.7921],\n",
      "        [-0.2387, -0.8946, -0.3868,  0.9539,  0.4227, -1.6187, -1.3766,  0.5460,\n",
      "          0.3895,  0.4823,  0.9322,  0.2423, -0.5093,  0.5077,  0.6841, -0.3679,\n",
      "          0.8145, -0.8067, -1.0406,  1.1993],\n",
      "        [-0.1573,  0.6340,  0.6209,  1.0411, -0.7470, -2.3066, -0.7299,  0.2309,\n",
      "         -0.1376,  0.5543, -0.3743,  1.4747, -0.7927,  0.0891,  1.8826,  1.3366,\n",
      "         -0.7287, -0.6109,  0.0521, -0.5148],\n",
      "        [ 0.0459, -1.4416,  0.0007, -0.4745, -0.2722, -0.4629, -2.3617,  0.7347,\n",
      "         -1.6845, -2.0819,  1.2072, -1.1969, -1.1631,  0.3365, -0.2932,  1.7725,\n",
      "          1.6847, -0.6387,  1.3334, -0.6876],\n",
      "        [-1.2298, -0.3286, -1.1785, -0.0073, -0.3857,  0.3422, -0.2071,  1.3424,\n",
      "         -0.8464, -0.0420, -1.9486, -2.1149,  0.9074, -0.8289, -2.1534,  0.2712,\n",
      "         -1.3843,  0.1435,  0.4115,  0.6914]])\n",
      "tensor([[ 0.3477,  1.7881,  0.1020, -3.0489,  0.7468,  0.5973,  0.5773, -0.0708,\n",
      "         -1.3510,  0.0036, -0.4196, -1.4115,  0.2081,  1.3612,  1.8832, -2.0351,\n",
      "         -0.8593, -0.6753,  0.5418,  0.1723],\n",
      "        [-0.4780, -0.3307, -0.5252, -0.2710,  0.3715, -1.2678, -0.4747,  0.7486,\n",
      "          0.6462,  0.0216, -1.3910, -0.6312, -0.2180,  0.3948,  0.9092, -0.6908,\n",
      "          0.6315, -0.7504, -1.6323, -2.4337],\n",
      "        [-0.3478,  0.1459,  1.4962,  0.8018,  0.2325, -1.3683, -0.2767, -0.6959,\n",
      "          0.4707, -1.4066, -1.0317, -0.1964,  0.7980, -0.6775, -1.5452,  0.4839,\n",
      "         -0.0455, -1.1354,  1.3209, -3.0151],\n",
      "        [ 1.4615, -1.8403, -1.8994, -1.1997, -0.0858,  1.6973,  1.0535,  0.3474,\n",
      "          1.3348, -1.0051,  0.3828, -0.0168,  0.0653,  1.1355, -0.2066,  0.1851,\n",
      "         -0.8155,  0.0409,  0.7851,  1.7631],\n",
      "        [-0.5739, -0.8242,  0.1789,  0.7699, -2.2492,  1.8560,  0.9774,  0.5689,\n",
      "         -0.2137, -0.6988, -0.1610, -1.2823, -0.8182,  1.5304,  0.6233,  0.4378,\n",
      "          0.3209,  0.2028, -0.4783,  2.6814],\n",
      "        [ 0.1592, -0.8178,  0.0085,  1.1814,  0.1288, -0.1295, -1.0593, -1.0653,\n",
      "         -0.6312, -1.1314, -0.1144, -0.9894,  0.7163, -0.0964,  0.1577, -1.4139,\n",
      "          0.1347, -1.7582, -3.4288,  0.7921],\n",
      "        [-0.2387, -0.8946, -0.3868,  0.9539,  0.4227, -1.6187, -1.3766,  0.5460,\n",
      "          0.3895,  0.4823,  0.9322,  0.2423, -0.5093,  0.5077,  0.6841, -0.3679,\n",
      "          0.8145, -0.8067, -1.0406,  1.1993],\n",
      "        [-0.1573,  0.6340,  0.6209,  1.0411, -0.7470, -2.3066, -0.7299,  0.2309,\n",
      "         -0.1376,  0.5543, -0.3743,  1.4747, -0.7927,  0.0891,  1.8826,  1.3366,\n",
      "         -0.7287, -0.6109,  0.0521, -0.5148],\n",
      "        [ 0.0459, -1.4416,  0.0007, -0.4745, -0.2722, -0.4629, -2.3617,  0.7347,\n",
      "         -1.6845, -2.0819,  1.2072, -1.1969, -1.1631,  0.3365, -0.2932,  1.7725,\n",
      "          1.6847, -0.6387,  1.3334, -0.6876],\n",
      "        [-1.2298, -0.3286, -1.1785, -0.0073, -0.3857,  0.3422, -0.2071,  1.3424,\n",
      "         -0.8464, -0.0420, -1.9486, -2.1149,  0.9074, -0.8289, -2.1534,  0.2712,\n",
      "         -1.3843,  0.1435,  0.4115,  0.6914]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "pytorch_tensor1=torch.Tensor(numpy_tensor)\n",
    "pytorch_tensor2=torch.from_numpy(numpy_tensor)\n",
    "print(pytorch_tensor1)\n",
    "print(pytorch_tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以使用**两种方式**将pytorch tensor转换为numpy ndarray.\n",
    "- `pytorch_tensor.numpy()`\n",
    "- `pytorch_tensor.cpu().numpy()`\n",
    "\n",
    "要注意 GPU 上的 Tensor 不能直接转换为 NumPy ndarray，需要使用.cpu()先将 GPU 上的 Tensor 转到 CPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.4766820e-01  1.7881441e+00  1.0196557e-01 -3.0489385e+00\n",
      "   7.4683952e-01  5.9729457e-01  5.7725328e-01 -7.0792280e-02\n",
      "  -1.3510040e+00  3.5981829e-03 -4.1961822e-01 -1.4114531e+00\n",
      "   2.0811097e-01  1.3612109e+00  1.8832421e+00 -2.0351315e+00\n",
      "  -8.5929310e-01 -6.7529601e-01  5.4178405e-01  1.7229411e-01]\n",
      " [-4.7804976e-01 -3.3073229e-01 -5.2518636e-01 -2.7100757e-01\n",
      "   3.7146404e-01 -1.2677985e+00 -4.7466570e-01  7.4856710e-01\n",
      "   6.4624727e-01  2.1555670e-02 -1.3909700e+00 -6.3121265e-01\n",
      "  -2.1798286e-01  3.9482734e-01  9.0921348e-01 -6.9077116e-01\n",
      "   6.3145703e-01 -7.5043857e-01 -1.6323138e+00 -2.4336519e+00]\n",
      " [-3.4777248e-01  1.4593977e-01  1.4962105e+00  8.0181503e-01\n",
      "   2.3249163e-01 -1.3682561e+00 -2.7667221e-01 -6.9592667e-01\n",
      "   4.7068948e-01 -1.4066013e+00 -1.0316694e+00 -1.9641460e-01\n",
      "   7.9799080e-01 -6.7745858e-01 -1.5452449e+00  4.8385838e-01\n",
      "  -4.5532495e-02 -1.1353710e+00  1.3209026e+00 -3.0151110e+00]\n",
      " [ 1.4614625e+00 -1.8402822e+00 -1.8994191e+00 -1.1997403e+00\n",
      "  -8.5754640e-02  1.6972942e+00  1.0535088e+00  3.4743884e-01\n",
      "   1.3348346e+00 -1.0050879e+00  3.8279352e-01 -1.6775187e-02\n",
      "   6.5259255e-02  1.1355478e+00 -2.0661041e-01  1.8512931e-01\n",
      "  -8.1545657e-01  4.0945310e-02  7.8509510e-01  1.7631149e+00]\n",
      " [-5.7387000e-01 -8.2415968e-01  1.7892447e-01  7.6987684e-01\n",
      "  -2.2492337e+00  1.8560495e+00  9.7739989e-01  5.6891716e-01\n",
      "  -2.1370800e-01 -6.9877970e-01 -1.6101792e-01 -1.2823142e+00\n",
      "  -8.1821376e-01  1.5303819e+00  6.2332183e-01  4.3779522e-01\n",
      "   3.2090077e-01  2.0275979e-01 -4.7828558e-01  2.6814408e+00]\n",
      " [ 1.5920529e-01 -8.1778485e-01  8.4842844e-03  1.1813681e+00\n",
      "   1.2884480e-01 -1.2949128e-01 -1.0593458e+00 -1.0652851e+00\n",
      "  -6.3121891e-01 -1.1313746e+00 -1.1435013e-01 -9.8943293e-01\n",
      "   7.1634752e-01 -9.6435457e-02  1.5769753e-01 -1.4139062e+00\n",
      "   1.3469245e-01 -1.7581954e+00 -3.4287825e+00  7.9214263e-01]\n",
      " [-2.3873226e-01 -8.9458829e-01 -3.8676453e-01  9.5394289e-01\n",
      "   4.2265666e-01 -1.6187117e+00 -1.3766284e+00  5.4604340e-01\n",
      "   3.8947257e-01  4.8232016e-01  9.3216288e-01  2.4233605e-01\n",
      "  -5.0934917e-01  5.0770348e-01  6.8409014e-01 -3.6786771e-01\n",
      "   8.1446183e-01 -8.0673730e-01 -1.0406111e+00  1.1992515e+00]\n",
      " [-1.5730672e-01  6.3398814e-01  6.2093139e-01  1.0410933e+00\n",
      "  -7.4696934e-01 -2.3065577e+00 -7.2986817e-01  2.3092091e-01\n",
      "  -1.3763875e-01  5.5426472e-01 -3.7432742e-01  1.4747214e+00\n",
      "  -7.9266870e-01  8.9071974e-02  1.8825753e+00  1.3365613e+00\n",
      "  -7.2871268e-01 -6.1089182e-01  5.2052174e-02 -5.1484406e-01]\n",
      " [ 4.5944698e-02 -1.4416128e+00  6.8031834e-04 -4.7452462e-01\n",
      "  -2.7222970e-01 -4.6290034e-01 -2.3616652e+00  7.3473382e-01\n",
      "  -1.6845340e+00 -2.0818903e+00  1.2072127e+00 -1.1969066e+00\n",
      "  -1.1630974e+00  3.3646551e-01 -2.9315636e-01  1.7725450e+00\n",
      "   1.6847440e+00 -6.3874727e-01  1.3333701e+00 -6.8758041e-01]\n",
      " [-1.2297502e+00 -3.2862324e-01 -1.1784946e+00 -7.2965110e-03\n",
      "  -3.8572428e-01  3.4222591e-01 -2.0710476e-01  1.3423690e+00\n",
      "  -8.4641522e-01 -4.2049289e-02 -1.9486159e+00 -2.1149302e+00\n",
      "   9.0743554e-01 -8.2885766e-01 -2.1533830e+00  2.7123272e-01\n",
      "  -1.3842876e+00  1.4349918e-01  4.1148469e-01  6.9138604e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 如果pytorch tensor在cpu上\n",
    "numpy_array=pytorch_tensor1.numpy()\n",
    "# 如果pytorch tensor在gpu上\n",
    "numpy_array2=pytorch_tensor1.cpu().numpy()\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Tensor使用GPU加速**\n",
    "\n",
    "我们可以使用**两种方式**将Tensor放到GPU上\n",
    "- 第一种方式是定义cuda数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6777, -0.3711, -0.3406,  0.3745,  0.6361, -1.4560, -0.1334,  0.8859,\n",
      "         -1.5605,  1.5876, -0.4878, -2.3333, -0.1123, -0.3674, -0.8516,  0.5119,\n",
      "          0.5832, -0.3235, -0.1700, -0.0802],\n",
      "        [ 0.4313, -1.3679,  0.1289, -0.5501,  0.6701,  0.5579, -0.4278, -1.2490,\n",
      "         -1.3132, -0.0976, -0.9721, -1.6348,  1.9039,  1.2731,  1.2103,  0.6920,\n",
      "          2.2081, -0.3208,  0.8248, -0.0966],\n",
      "        [ 0.7765, -0.4996,  2.7369, -0.1760, -0.3320, -0.8590,  0.1085,  0.7133,\n",
      "          0.7077,  0.5117, -0.3836, -1.0927, -1.5854,  0.9764, -0.9618, -0.7143,\n",
      "         -0.3837, -0.3497,  0.2725,  0.4042],\n",
      "        [-0.2872,  0.2916, -0.5283,  0.3136,  2.0496,  0.2895,  0.6578,  0.0841,\n",
      "          0.6005, -0.0792,  1.4756,  0.3967,  0.9111,  0.5229, -0.4172, -0.5235,\n",
      "         -0.2882, -1.4716, -0.9194,  0.3850],\n",
      "        [-0.4937,  0.0048,  0.2866,  0.8307, -0.8006,  1.0387,  1.5810,  0.2094,\n",
      "         -1.5906, -2.1610, -0.7815, -1.1900, -0.5350, -0.7430,  1.7588,  1.0452,\n",
      "          0.3747,  1.2028,  0.0399, -1.0532],\n",
      "        [-0.0718,  0.9244, -2.2396,  0.2713, -0.2426,  1.3213, -0.5370,  1.2198,\n",
      "         -0.5694,  0.9449, -2.4275,  0.6859,  1.5341, -0.5432,  0.5833,  0.1974,\n",
      "         -0.7494,  0.4759,  0.2194, -0.6635],\n",
      "        [-2.6070, -1.0427, -0.5358,  0.8994,  0.6923, -0.6150, -0.8113, -0.1318,\n",
      "         -1.3057,  0.7413,  0.9758,  1.6619,  0.2282,  0.0758,  0.1838,  0.7445,\n",
      "          0.7036,  0.1879,  0.7552,  0.7540],\n",
      "        [ 0.3720, -0.9820,  0.0222,  0.0753, -1.5769,  0.3454, -0.9319, -0.1015,\n",
      "          0.6725,  0.8856, -0.1389,  0.7853, -0.9101, -0.3734, -0.2168,  1.4989,\n",
      "         -0.5808,  0.1451,  0.9560,  0.0337],\n",
      "        [ 0.7858, -1.7821,  0.9806, -0.4599, -0.2095, -2.0475,  0.2169, -0.6114,\n",
      "          1.5375, -0.3034, -0.6917, -0.6451,  1.9149,  0.9366,  0.1090,  1.5313,\n",
      "         -0.5107, -0.8155,  2.4136, -0.6223],\n",
      "        [-0.5853, -1.3209, -1.4995,  0.5600,  0.2472, -0.4903,  0.6194, -1.0593,\n",
      "         -1.1534,  3.1138,  0.7780,  2.3198,  0.1962,  1.4268,  0.6352, -1.4884,\n",
      "          0.7305,  0.6790, -1.4524, -0.9889]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dtype=torch.cuda.FloatTensor\n",
    "gpu_tensor=torch.randn(10,20).type(dtype)\n",
    "print(gpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二种方式更简单, `tensor.cuda()`, 直接将tensor放到GPU上,类型跟之前的保持一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8601, -1.1352, -2.0012,  0.8359,  0.5503,  2.5196, -1.0650, -0.9062,\n",
      "          0.5819, -1.1395,  0.2407, -0.7685,  0.0436,  0.6902, -0.2149,  0.4144,\n",
      "         -0.5558,  2.1616,  0.6707, -0.3136],\n",
      "        [-1.0492, -0.3998, -1.9461, -0.0103, -0.6489,  0.3162,  0.1436,  0.5702,\n",
      "         -0.9237,  1.2309,  1.0063,  0.8195,  0.3772,  0.4709, -0.6586, -0.4060,\n",
      "          0.2609,  0.6761, -1.2853, -1.0977],\n",
      "        [-0.4791, -1.4695, -0.8223,  0.9505, -1.7465,  1.0297, -0.2031,  0.0983,\n",
      "          0.3556,  0.8551, -0.3529, -0.5691, -0.7239,  1.2712, -0.2156, -0.7473,\n",
      "          3.1520,  0.3483,  0.6345, -0.4267],\n",
      "        [ 0.0374, -0.5012, -1.4752, -1.3636,  0.3391,  0.2749,  0.8439,  0.4496,\n",
      "          0.4624,  1.2606, -0.8003,  0.1185,  1.2116, -1.1107,  0.1377, -0.3489,\n",
      "          0.0246,  0.9314,  2.0422,  0.8103],\n",
      "        [-1.1382,  0.1428, -0.4872,  0.3583, -0.1730, -0.4785, -0.7477,  0.8444,\n",
      "         -0.5530, -3.5062, -0.5724, -0.6495, -1.5996,  1.3975, -0.9476, -0.6514,\n",
      "         -0.1344, -1.4758, -1.1462, -0.1142],\n",
      "        [-0.1493, -0.1102,  0.2076, -3.0709, -1.1263, -0.2054, -0.6125,  0.3059,\n",
      "         -0.8843, -1.1546,  0.0487,  1.1081,  2.5631, -0.2607,  0.5455, -0.6658,\n",
      "          1.6174, -0.5416,  0.9654, -0.9237],\n",
      "        [-1.2673,  0.0910,  1.3479, -0.9603, -0.3060,  1.2664,  0.3907,  0.2482,\n",
      "         -0.5880,  0.2673,  0.3657, -2.2291,  0.9416,  0.8937, -0.8830,  0.1644,\n",
      "          0.2555, -0.2131,  1.7744,  1.0700],\n",
      "        [ 1.3541,  0.3115,  0.3868,  0.2502,  1.3041, -1.1503, -1.0257,  0.7189,\n",
      "          1.8913,  1.1246, -2.1716, -0.0142, -0.1214,  1.5537,  1.0626, -0.7998,\n",
      "          0.8568,  1.3299, -1.9622, -0.6421],\n",
      "        [-0.2376,  0.5609, -0.0621, -1.2865, -0.0227, -0.1252, -0.7121, -1.0538,\n",
      "          1.0675,  1.2950, -0.6552,  0.0801,  1.3657, -0.7823,  2.1660, -0.1567,\n",
      "         -0.1564,  0.0156,  0.9266,  0.4913],\n",
      "        [ 1.4759,  0.5581, -1.1170, -0.9729, -0.6767, -0.5935, -0.6794,  1.1155,\n",
      "          0.4243, -1.6862,  0.9120, -1.0299,  0.4516,  2.1583, -0.7799, -0.3812,\n",
      "          2.1287,  0.2181,  0.0851,  0.3109]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpu_tensor = torch.randn(10, 20).cuda(0) # 将 tensor 放到第一个 GPU 上\n",
    "#gpu_tensor = torch.randn(10, 20).cuda(1) # 将 tensor 放到第二个 GPU 上, 因为我们只有一个GPU,所以我们注释掉这行代码\n",
    "print(gpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch 将tensor放回CPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8601, -1.1352, -2.0012,  0.8359,  0.5503,  2.5196, -1.0650, -0.9062,\n",
      "          0.5819, -1.1395,  0.2407, -0.7685,  0.0436,  0.6902, -0.2149,  0.4144,\n",
      "         -0.5558,  2.1616,  0.6707, -0.3136],\n",
      "        [-1.0492, -0.3998, -1.9461, -0.0103, -0.6489,  0.3162,  0.1436,  0.5702,\n",
      "         -0.9237,  1.2309,  1.0063,  0.8195,  0.3772,  0.4709, -0.6586, -0.4060,\n",
      "          0.2609,  0.6761, -1.2853, -1.0977],\n",
      "        [-0.4791, -1.4695, -0.8223,  0.9505, -1.7465,  1.0297, -0.2031,  0.0983,\n",
      "          0.3556,  0.8551, -0.3529, -0.5691, -0.7239,  1.2712, -0.2156, -0.7473,\n",
      "          3.1520,  0.3483,  0.6345, -0.4267],\n",
      "        [ 0.0374, -0.5012, -1.4752, -1.3636,  0.3391,  0.2749,  0.8439,  0.4496,\n",
      "          0.4624,  1.2606, -0.8003,  0.1185,  1.2116, -1.1107,  0.1377, -0.3489,\n",
      "          0.0246,  0.9314,  2.0422,  0.8103],\n",
      "        [-1.1382,  0.1428, -0.4872,  0.3583, -0.1730, -0.4785, -0.7477,  0.8444,\n",
      "         -0.5530, -3.5062, -0.5724, -0.6495, -1.5996,  1.3975, -0.9476, -0.6514,\n",
      "         -0.1344, -1.4758, -1.1462, -0.1142],\n",
      "        [-0.1493, -0.1102,  0.2076, -3.0709, -1.1263, -0.2054, -0.6125,  0.3059,\n",
      "         -0.8843, -1.1546,  0.0487,  1.1081,  2.5631, -0.2607,  0.5455, -0.6658,\n",
      "          1.6174, -0.5416,  0.9654, -0.9237],\n",
      "        [-1.2673,  0.0910,  1.3479, -0.9603, -0.3060,  1.2664,  0.3907,  0.2482,\n",
      "         -0.5880,  0.2673,  0.3657, -2.2291,  0.9416,  0.8937, -0.8830,  0.1644,\n",
      "          0.2555, -0.2131,  1.7744,  1.0700],\n",
      "        [ 1.3541,  0.3115,  0.3868,  0.2502,  1.3041, -1.1503, -1.0257,  0.7189,\n",
      "          1.8913,  1.1246, -2.1716, -0.0142, -0.1214,  1.5537,  1.0626, -0.7998,\n",
      "          0.8568,  1.3299, -1.9622, -0.6421],\n",
      "        [-0.2376,  0.5609, -0.0621, -1.2865, -0.0227, -0.1252, -0.7121, -1.0538,\n",
      "          1.0675,  1.2950, -0.6552,  0.0801,  1.3657, -0.7823,  2.1660, -0.1567,\n",
      "         -0.1564,  0.0156,  0.9266,  0.4913],\n",
      "        [ 1.4759,  0.5581, -1.1170, -0.9729, -0.6767, -0.5935, -0.6794,  1.1155,\n",
      "          0.4243, -1.6862,  0.9120, -1.0299,  0.4516,  2.1583, -0.7799, -0.3812,\n",
      "          2.1287,  0.2181,  0.0851,  0.3109]])\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor=gpu_tensor.cpu()\n",
    "print(cpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**我们也能访问到Tensor的一些属性**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的大小: `tensor.shape`, `tensor.size()`,注意`shape`后边没有括号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.shape)\n",
    "print(pytorch_tensor1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的数据类型: `tensor.type()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的维度: `tensor.dim()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 得到tensor的所有元素的个数: `tensor.numel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(pytorch_tensor1.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "创建一个类型是float64, 大小是3\\*2,随机初始化的tensor,将其转化为numpy的ndarray,输出其数据类型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5533,  0.8228],\n",
      "        [-0.0192,  1.2652],\n",
      "        [-0.6564,  0.9479]], dtype=torch.float64)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "mytensor=torch.randn(3,2).type(torch.DoubleTensor)\n",
    "myarray=mytensor.numpy()\n",
    "print(mytensor)\n",
    "print(myarray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor的操作\n",
    "Tensor 操作中的 api 和 NumPy 非常相似，如果你熟悉 NumPy 中的操作，那么 tensor 基本是一致的，下面我们来列举其中的一些操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.ones()`生成全`1`tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(2,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `torch.type()`得到tensor类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 转换tensor数据类型为整形: `tensor.long()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "x=x.long()\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将整形tensor转换为float类型: `tensor.float()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "x=x.float()\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 沿着行取最大值: `torch.max(tensor, dim=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6204, -0.4077, -1.3994],\n",
      "        [-0.8982,  0.4406, -1.8149],\n",
      "        [-0.8666,  1.0114, -0.7348],\n",
      "        [ 2.0932, -2.4719, -0.3610]])\n",
      "tensor([1.6204, 0.4406, 1.0114, 2.0932]) tensor([0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(4,3)\n",
    "print(x)\n",
    "max_value, max_idx=torch.max(x, dim=-1)\n",
    "print(max_value, max_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 沿着行对`x`求和: `torch.sum(tensor, dim=)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1867, -2.2725, -0.5900, -0.7398])\n"
     ]
    }
   ],
   "source": [
    "sum_x=torch.sum(x,dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 增加维度或者减少维度: `tensor.unsqueeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "x=x.unsqueeze(0) #在第一维度增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x=x.unsqueeze(1) #在第二维度增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x=x.squeeze(0) #减少第一个维度\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x=x.squeeze() #将tensor中所有1维都删掉\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用`permute`和`transpose`进行维度交换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([4, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "print(x.shape)\n",
    "\n",
    "x=x.permute(1,0,2) #将第0维和第1维交换\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x=x.transpose(0,2) #将第0维和第2维交换\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用`view`对tensor进行reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([12, 5])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4,5)\n",
    "print(x.shape)\n",
    "\n",
    "x=x.view(-1,5)\n",
    "print(x.shape)\n",
    "\n",
    "x=x.view(3,20)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 两个tensor求和: `torch.add(tensor1,tensor2)`或者`tensor1+tensor2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4661,  0.0368, -3.1299, -0.4008],\n",
      "        [ 1.9232, -0.9474,  1.1776,  3.5262],\n",
      "        [-0.3276,  1.3257,  0.6753, -0.8982]])\n",
      "tensor([[-0.4661,  0.0368, -3.1299, -0.4008],\n",
      "        [ 1.9232, -0.9474,  1.1776,  3.5262],\n",
      "        [-0.3276,  1.3257,  0.6753, -0.8982]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3,4)\n",
    "y=torch.randn(3,4)\n",
    "z1=torch.add(x,y)\n",
    "z2=x+y\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch大多数操作支持inplace原地操作,也就是直接对tensor进行操作而不需要开辟内存空间,方式非常简单,一般是在操作的符号后面加`_`,比如:\n",
    "- `unsqueeze`进行inplace操作:`unsqueeze_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(3,3)\n",
    "print(x.shape)\n",
    "#unsqueeze进行\n",
    "x.unsqueeze_(0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `transpose()`进行inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x.transpose_(1,0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `add`进行inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(3,3)\n",
    "y=torch.ones(3,3)\n",
    "print(x)\n",
    "\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小练习\n",
    "创建一个float32, 4\\*4的全为1的矩阵, 将矩阵中间2\\*2的矩阵,全部修改为2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 2., 2., 1.],\n",
      "        [1., 2., 2., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.ones(4,4).float()\n",
    "x[1:3,1:3]=2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. Variable\n",
    "tensor 是 PyTorch 中的完美组件，但是构建神经网络还远远不够，我们需要能够构建计算图的 tensor，这就是 **Variable**。Variable 是对 tensor 的封装，操作和 tensor 是一样的，但是每个 Variabel都有三个属性，Variable 中的 tensor本身`.data`，对应 tensor 的梯度`.grad`以及这个 Variable 是通过什么方式得到的`.grad_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将tensor变成Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor=torch.randn(10,5)\n",
    "y_tensor=torch.randn(10,5)\n",
    "\n",
    "x=Variable(x_tensor, requires_grad=True) #默认Variable是不需要求梯度的, 所以我们需要用这个方式申明需要对其进行求梯度\n",
    "y=Variable(y_tensor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 得到Variable的数值及获得方式: `variable.data`,`variable.grad_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.sum(x+y) #不指定dim就把所有元素相加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.6818)\n",
      "<SumBackward0 object at 0x000002C8B510F2E8>\n"
     ]
    }
   ],
   "source": [
    "print(z.data)\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 得到Variable的梯度: `variable.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3506, -0.6990, -0.5743,  1.0694, -1.5128],\n",
      "        [ 1.8279, -1.2237, -0.0016, -0.7818,  0.6222],\n",
      "        [ 0.1577, -1.4566,  0.9656,  1.5383, -1.1200],\n",
      "        [-0.4983, -0.1309,  0.9987, -1.5305, -0.0332],\n",
      "        [-1.6599,  1.3826,  0.0984,  0.1855,  0.1615],\n",
      "        [ 1.1625, -0.1463,  0.3584, -1.2116,  1.0982],\n",
      "        [ 1.8765,  0.9613, -0.4388, -1.0859, -0.1459],\n",
      "        [-0.4789,  0.4323, -0.7594,  0.4259,  0.7395],\n",
      "        [-0.5352,  1.2512, -1.4089,  0.4248,  1.5354],\n",
      "        [-0.4910,  0.2200, -0.3206, -0.9860, -1.6786]])\n",
      "tensor([[ 1.3893, -0.8226,  0.7317,  0.0328,  0.1455],\n",
      "        [-0.9195, -1.5158,  1.1552,  1.7297,  0.3118],\n",
      "        [-1.1521,  1.4480,  0.9226, -0.0635, -0.2216],\n",
      "        [-0.5374,  0.2624, -1.2691,  0.2510, -0.6975],\n",
      "        [-1.0064,  0.0821, -0.0102, -1.0965, -2.1435],\n",
      "        [ 1.2014,  2.0558, -1.8242,  1.2707,  0.4972],\n",
      "        [-0.2413,  1.2036, -1.6684,  1.0253, -1.7398],\n",
      "        [-1.1352, -0.2039, -0.4351, -0.4966, -0.5288],\n",
      "        [-0.5196, -0.1676,  1.7591, -0.8061,  1.7555],\n",
      "        [ 0.1072, -0.3074,  0.1803, -1.2659,  0.3616]])\n",
      "tensor([[4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.]])\n",
      "tensor([[4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.],\n",
      "        [4., 4., 4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "#求x和y的梯度\n",
    "z.backward()\n",
    "\n",
    "print(x.data)\n",
    "print(y.data)\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小练习\n",
    "尝试构建一个函数 $y=x^2$,然后求$x=2$的导数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd4VFX+x/H3mcmkA4EkBEISQggtIr0jioJddO2ADd0Ve1m36Kqr7rq6lrW7Fqyrgti7oigoiLQAkZYAISEVUgghCSkkM+f3R6I/RcoQMjn3znxfz5NHMl4yn0vw4825556jtNYIIYSwD4fpAEIIIQ6PFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQthMkC++aExMjE5OTvbFlxZCCL+0atWqcq11rDfH+qS4k5OTSU9P98WXFkIIv6SUyvP2WBkqEUIIm5HiFkIIm5HiFkIIm5HiFkIIm5HiFkIIm5HiFkIIm5HiFkIIm7FMcdc3unlhUQ4/bC03HUUIIQ7bwqxSXlmSy94mj8/fyzLFHeRQvLA4h5cW55qOIoQQh+3Z77byvx+24XIqn7+XdYrb6eC84Qks3FTKjt31puMIIYTXcspqWJFbwQUjE1EqgIob4IIRiXg0vLuqwHQUIYTw2lvpBTgdivOGJbTL+1mquJNjIhibEs1b6QV4PNp0HCGEOKRGt4f3VhVyQv+udO0Y2i7vaaniBpg6KpGCijqW5uw0HUUIIQ7pm8xSymv2MnVkYru9p+WK++SjutEpzMWbK/JNRxFCiEOauzKfbh1DOa6vVyuytgnLFXeoy8nZQ3vw1YYSKvbsNR1HCCEOqLiyju82l3H+iASCnO1Xp5YrboALRyay1+3hgzVFpqMIIcQBvZNeiNbNEyvakyWLe0D3jgxOjOKtlfloLTcphRDW4/Zo3k4v4JjUGBK7hLfre1uyuAGmjkxkc0kNawoqTUcRQojfWJJdTlFlHRe2403Jn1i2uKcMjic82MlcuUkphLCguSvz6Rzu4qSj4tr9vS1b3JEhQUwZFM8nP26nur7RdBwhhPhZeU0D8zeWcM6wBEKCnO3+/pYtboALRyVS1+jmkx+3m44ihBA/+2B1EY1ubWSYBCxe3EMTo+gX14G5K2W4RAhhDVpr3lyRz7CkKPrGdTCSwdLFrZRi+ugk1hbuZm2h3KQUQpi3NGcnOeV7uGh0T2MZLF3cAGcP60GYy8mc5XLVLYQwb/byfDqFuTh9UHdjGSxf3B1DXZw5OJ6PMoqpkpuUQgiDyqob+HL9Ds4bnkCoq/1vSv7E8sUNcNGYJOoa3XwkT1IKIQx6Z1UBTR7N9NFJRnPYorgHJUQxsEdHZi+XJymFEGZ4PJo5y/MZk9KF3rGRRrN4VdxKqT8qpTYopdYrpd5USrXPorO/cNHonmTtqGZ1/q72fmshhGDRljIKd9UZvSn5k0MWt1KqB3AjMEJrPRBwAlN9HWxfZw6OJzIkiNnL5CalEKL9zV6eT3REMCcf1c10FK+HSoKAMKVUEBAOFPsu0v5FhARx9tAefLpuO5W1styrEKL9bN9dx4KsUi4YmUhwkPkR5kMm0FoXAf8B8oHtwG6t9Vf7HqeUmqmUSldKpZeVlbV9UmD66CT2Nnl4d1WhT76+EELsz1srC3B7NNNGmr0p+RNvhko6A2cBvYB4IEIpdfG+x2mtZ2mtR2itR8TG+mYniAHdOzIsKYo5cpNSCNFOmtwe5q4o4Ni+sSRFt+/yrQfizTX/ZCBXa12mtW4E3gfG+TbWgV00uic55XtkT0ohRLtYkFXKjqp6LjI8BfCXvCnufGCMUipcKaWASUCmb2Md2OmDutMpzCU3KYUQ7WL28nziOoYwqX9X01F+5s0Y93LgXWA1sK7l98zyca4DCnU5OX94Al9u2EFJVb2pGEKIALCtfA/fbS5j2qikdt1T8lC8SqK1vltr3V9rPVBrfYnWusHXwQ7m4jE9cWst65cIIXzq9WV5BDkU00dZZ5gEbPLk5L6SYyI4rm8sc1bks7fJYzqOEMIP1e5t4p30Ak4Z2I2uHdv9mcODsmVxA1w6tmfzgi8bdpiOIoTwQ80L2zVx6dhk01F+w7bFfVzfriR1Cef1pXmmowgh/IzWmteW5tG/WwdGJnc2Hec3bFvcTofi4jFJrNhWQeb2KtNxhBB+ZFXeLjK3V3Hp2GSaJ9NZi22LG+CCEYmEBDl4Ta66hRBt6H9L8+gQGsTvhsabjrJfti7uqPBgzhoSz4drithdJ5ssCCGOXGlVPV+s2875wxMJDw4yHWe/bF3cAJeOTaau0S3rlwgh2sSbK5o3S7hkrPnlWw/E9sU9sEcnhiVF8cayPDweWb9ECNF6jW4Pc1bkcWzfWHrFRJiOc0C2L26Ay8Ylk1u+h8XZ5aajCCFs7KsNJZRUNXCZha+2wU+K+5SB3YiJDOa1H7aZjiKEsLHXlm4joXMYE/tZZ12S/fGL4g4JcjJ9VBILNpWyrXyP6ThCCBvaULyb5bkVXDq2J06H9aYA/pJfFDc0r18S5FC8KlfdQohWeGXJNsKDnVw4wlrrkuyP3xR3146hnDEonnfSC6iql6mBQgjvlVU38HFGMecOS6BTuMt0nEPym+IGuGJ8L/bsdfNOukwNFEJ4b87yfPa6PcwYn2w6ilf8qriPTujEyOTOvPpDLm6ZGiiE8EJDk5vXl+VxfL9YesdGmo7jFb8qboDLx/eioKKOrzNLTEcRQtjApz9up7ymgcvH9zIdxWt+V9wnpcXRIyqMV5bkmo4ihLA4rTUvL8kltWskE/rEmI7jNb8r7iCng0vH9mRZTgUbinebjiOEsLCV23axobiKy8dbcxXAA/G74gaYOjKJMJeTV5dsMx1FCGFhryzJpVOYi3OGJpiOclj8srg7hbs4b3gCH2UUU15jdHtMIYRFFVTU8uWGHUwfnURYsNN0nMPil8UNMGN8MnvdHmYvkw2FhRC/9drSbSiluGSMtdcl2R+/Le7esZFM7BfL68vyqG90m44jhLCQmoYm5q5s3gg4PirMdJzD5rfFDXDlhBTKaxr4KKPIdBQhhIXMXZFPdX0TMyekmI7SKn5d3ON6R5PWvSMvLM6VtbqFEAA0uT28smQbo3p1YXBilOk4reLXxa2UYuaxKWSX1vDd5jLTcYQQFvD5+h0UVdbZ9mob/Ly4AU4f1J3unUKZtSjHdBQhhGFaa2Yt2kpKbAQn9Lf2mtsH4/fF7XI6uGJ8L5bm7GRdoTyQI0QgW5ZTwfqiKq6ckILD4mtuH4zfFzfA1FGJdAgJ4oXFctUtRCB7YXEOMZHBnD20h+koRyQgirtDqItpo5P4bN12CnfVmo4jhDBgS0k1C7JKuXRsMqEuez1ws6+AKG6AGeOSUTTvciGECDwvLs4l1OXgYhs+cLOvgCnu+KgwpgyOZ+6KfHbXyQ45QgSS0up6PlhTxPnDE+kSEWw6zhELmOIG+MOE5h1y3lwhj8ELEUhe+yGPRo+H3x9jnzW3Dyagivuo+E6MT43mlSW5NDTJY/BCBII9DU28sTyPk9LiSI6JMB2nTQRUcQNcfVxvSqoa+HCNPAYvRCB4c0U+lbWNXHVcb9NR2oxXxa2UilJKvauUylJKZSqlxvo6mK8ckxrDwB4dee67HNmXUgg/19Dk5sXFuYxJ6cKwpM6m47QZb6+4nwDmaa37A4OBTN9F8i2lFNdOTCW3fA/z1u8wHUcI4UMfriliR1U9105MNR2lTR2yuJVSHYFjgZcAtNZ7tdaVvg7mSycf1Y2UmAie/S4breWqWwh/5PZonv8uh4E9OtpqP0lveHPFnQKUAa8opdYopV5UStl6hN/pUFx1XArri6pYvKXcdBwhhA98uWEHOeV7uOa4VFvtJ+kNb4o7CBgGPKu1HgrsAW7b9yCl1EylVLpSKr2szPor8Z09NIFuHUN55tts01GEEG1Ma80z32aTEhPBKQO7mY7T5rwp7kKgUGu9vOXzd2ku8l/RWs/SWo/QWo+IjY1ty4w+ERzk4A8TerEsp4LV+btMxxFCtKHvs8tZX1TFVcel4LTxYlIHcsji1lrvAAqUUv1aXpoEbPRpqnYybVQSUeEunv12q+koQog29MzCrcR1DOF3Nl9M6kC8nVVyAzBbKbUWGALc77tI7SciJIjLxiYzf2MJm0uqTccRQrSBNfm7WJqzkysnpBASZO/FpA7Eq+LWWme0DIMM0lr/TmvtN2MLM8YlE+Zy8pxcdQvhF575diudwlxMG5VkOorPBNyTk/vqHBHMtFFJfPRjMfk7ZclXIexs045q5m8s4bJxyUSEBJmO4zMBX9zAzzcwnv1OZpgIYWdPLdhCRLCTK8Ynm47iU1LcQFzHUKaOTOTdVYWy0YIQNpVdWs1n67Zz2bhkosLtv3TrwUhxt7i6ZQGa576TsW4h7OjpBdmEuZz8wca7t3tLirtFfFQY5w1P5O2VhezYXW86jhDiMOSW7+HjH4u5eExPv9go4VCkuH/h2om98WgtV91C2Mx/F2bjcjq4MgCutkGK+1cSu4RzzrAevLkin9IqueoWwg7yd9bywZoiLhrdk9gOIabjtAsp7n1cd3wqTR7NrEU5pqMIIbzwzLfZPy8cFyikuPfRMzqCs4bE88byPMprGkzHEUIcROGuWt5dVci0kYnEdQw1HafdSHHvx3XHp9LQ5OGFxXLVLYSVPfvtVpTCr7Yl84YU9370jo1kyqB4Xl+ax0656hbCkoor63gnvZDzRyQSHxVmOk67kuI+gBsnpVLf6OZ5GesWwpKeWpCNRnPtxMC62gYp7gNK7dqB3w3pwWtLt1FaLTNMhLCS/J21vJNewLRRSSR0Djcdp91JcR/EjZP60OjWPLNQ5nULYSVPLtiC06G47nj/2gTYW1LcB5EcE8F5wxKYszyf4so603GEEMDWshreX13IxWN6BtRMkl+S4j6EGyalotE8vVBWDhTCCp74egshQU6uCcCx7Z9IcR9CQudwpo5M4u2VBbJetxCGbdpRzSdri5kxPpmYyMB4SnJ/pLi9cN3xqTgciicXbDEdRYiA9tj8zUQEBzEzQNYkORApbi906xTKJWN68v7qQnLKakzHESIgrS/azbwNO/j9Mb3oHAArAB6MFLeXrpnYm5AgJ49/LVfdQpjw6PzNdApz8fsJvUxHMU6K20sxkSHMGJ/MJ2uLydxeZTqOEAFlVd4uFmSVMvPYFDqGukzHMU6K+zBcdWwKHUKCePjLTaajCBEwtNY8+EUWMZEhXO7ne0l6S4r7MESFB3PNxFQWZJWyPGen6ThCBISFm0pZsa2Cmyb3ITzYf3duPxxS3Idpxrhk4jqG8MC8LLTWpuMI4dfcHs2DX2wiOTqcqSMTTcexDCnuwxQW7OSPk/uyJr+SrzaWmI4jhF/7cE0Rm0qq+fPJ/XA5pa5+In8SrXDe8AR6x0bw0Lwsmtwe03GE8Ev1jW4enb+Zo3t04rSB3U3HsRQp7lYIcjr4y8n92Vq2h/dWF5qOI4RfemNZHkWVddx2an8cDmU6jqVIcbfSyUfFMTQpisfmb6G+0W06jhB+paq+kacXZjOhTwzjU2NMx7EcKe5WUkpx6yn92VFVz6s/bDMdRwi/Muu7HCprG7n1lP6mo1iSFPcRGJMSzfH9YnlmYTaVtXtNxxHCL5RW1fPS97lMGRzPwB6dTMexJCnuI3Trqf2paWjiyW9k2Vch2sJ/vtpEk8fDn0/qazqKZUlxH6H+3TpywYhEXlu6TRagEuIIbSjezTurCrlsbDI9oyNMx7EsKe42cMtJfQkJcvDAF1mmowhhW1pr7vssk6gwFzdM6mM6jqVJcbeBrh1Cufb4VL7aWMLSrfIovBCt8U1mKT9s3cnNk/vSKUwWkjoYKe428vtjehHfKZR/fbYRj0cehRficDS6Pdz/eSYpsRFMH51kOo7leV3cSimnUmqNUupTXwayq1CXk1tP7c+G4ireX1NkOo4QtjJ7WR455Xu447QB8mi7Fw7nT+gmINNXQfzBmYPjGZIYxcNfZlG7t8l0HCGsbfZsSE5GOxycdPoY/lKezgn9u5pOZQteFbdSKgE4HXjRt3HsTSnF388YQElVA7MW5ZiOI4R1zZ4NM2dCXh5Ka+J3l3LNnAdRc+aYTmYL3l5xPw78FZAVlQ5heM8unD6oO89/l8P23XWm4whhTXfcAbW1v3rJUVfX/Lo4pEMWt1LqDKBUa73qEMfNVEqlK6XSy8rK2iygHd12Sn88WvPvz2V6oBD7lZ9/eK+LX/Hmins8cKZSahswFzhBKfXGvgdprWdprUdorUfExsa2cUx7SewSzlXH9ebjH4tZJjvlCPFbSQeYOXKg18WvHLK4tdZ/01onaK2TganAAq31xT5PZnPXHNebHlFh3PPxBlmzW4h97P3nvdS7Qn79Yng43HefmUA2I/NufCQs2Mnfz0gja0c1byzLMx1HCEuZlTCGv558PfXxCaAU9OwJs2bBRReZjmYLh1XcWutvtdZn+CqMvzn5qDgm9InhkfmbKa9pMB1HCEsoqqzj6YXZNF44jdCiAvB4YNs2Ke3DIFfcPqSU4u4pR1G3183D8zaZjiOEJdz/WfPjIHecPsBwEvuS4vax1K6R/P6YXryVXkBGQaXpOEIYtSS7nM/Wbee6iakkdA43Hce2pLjbwQ2T+tC1Qwh3f7Re1jERAavR7eHujzeQ1CWcK49NMR3H1qS420FkSBC3nzaAHwt3M3dlgek4QhjxypJcsktruOuMNEJdTtNxbE2Ku52cNSSeMSldeOCLTMqq5UalCCyFu2p5bP4WJg/oyqQBsh7JkZLibidKKe47+2jqGz3867ONpuMI0W601tz10QaUgn+cNRCllOlItifF3Y56x0ZyzcTefJRRzKLNgb0sgAgc89bvYEFWKbec2JceUWGm4/gFKe52ds3E3qTERHDnh+upb3SbjiOET1XXN3LPJxtI696RGeOSTcfxG1Lc7SzU5eRfZw8kv6KWpxfIzvDCvz3y1WZKqxv49zlHEyQbJLQZ+ZM0YFzvGM4Z1oPnF21lc0m16ThC+MSPBZX8b+k2Lh3Tk8GJUabj+BUpbkPuOG0AESFB3PHBOpnbLfxOk9vD395fR9cOIfzp5H6m4/gdKW5DoiNDuP20Aazctos3V8oaxMK/vLwkl43bq7hnylF0DJUd29uaFLdB5w9PYFzvaP79eRZFlbJbjvAPOWU1PPLVZiYPiOOUgd1Mx/FLUtwGKaV44JxBuD2av72/Dq1lyETYm9uj+eu7awkJcnD/2TJn21ekuA1Lig7n1lP6sWhzGe+uKjQdR4gj8trSbaTn7eKuKUfRtWOo6Th+S4rbAi4dm8yo5C7c++lGSqrqTccRolXydu7hoXmbmNgvlnOH9TAdx69JcVuAw6F48LxBNDR5uOMDGTIR9uPxaG59by1BDsW/zzlahkh8TIrbInrFRPCXk/vxdWYpH2UUm44jxGGZvSKfZTkV3HH6ALp3ksfafU2K20IuH9+LYUlR3PPJBkqrZchE2EPhrloe+DyTCX1iuHBkouk4AUGK20KcDsVD5w2mdq+b22WWibABj0fzl3fWAsgQSTuS4raY1K6R/LVlyEQ2XRBW99L3uSzN2cldU9JkK7J2JMVtQVeM78X41Gju/XQj28r3mI4jxH5lbq/i4S83cVJaHBeMkCGS9iTFbUEOh+I/5w8myKG4+a0Mmtwe05GE+JX6Rjd/fCuDjmEuGSIxQIrborp3CuO+s48mo6CS/y7cajqOEL/yyFebyNpRzcPnDSI6MsR0nIAjxW1hUwbH87sh8Ty5YAtr8neZjiMEAD9kl/PC4lwuHpPE8f1l/0gTpLgt7h9nDSSuQwi3vP0jtXubTMcRAW53bSN/eudHUmIiuOO0NNNxApYUt8V1CnPxyAVD2LZzD//8RDYZFuZorbn9w3WUVTfw2IVDCAt2mo4UsKS4bWBs72iuOa43c1cW8FFGkek4IkDNWZHPZ2u3c8tJfWVHG8OkuG3ilhP7MqJnZ25/fx05ZTWm44gAs7G4in98spFj+8Zy9bG9TccJeFLcNhHkdPDktKG4ghxcN2eN7BAv2k1NQxPXz1lNVJiLRy8YjMMhU/9Mk+K2kfioMB69YDCZ26v412cy3i18T2vNnR+sY9vOPTw5bSgxMvXPEqS4beaE/nHMPDaFN5Y1jzcK4UvvpBfyYUYxN0/uy5iUaNNxRAspbhv6y8n9GJIYxW3vrSVvpzwSL3xjc0k1d328nnG9o7nu+FTTccQvSHHbkMvp4OnpQ1EKrnljNXV7ZbxbtK3q+kaufmMVkSFBPD51CE4Z17YUKW6bSugczuNTh5C5o4q/vb9WloAVbcbj0dzy9o/k7azl6enD6NpB9o60mkMWt1IqUSm1UCmVqZTaoJS6qT2CiUM7oX8ct0zuy4cZxbyyZJvpOMJPPL0wm/kbS7jz9AEyrm1R3lxxNwF/0loPAMYA1yml5FlXi7ju+FROSovjvs8zWbp1p+k4wua+ySzhsa83c87QHswYl2w6jjiAQxa31nq71np1y6+rgUxAtnC2CIdD8cgFg0mODuf6OaspqqwzHUnYVE5ZDTfPzSCte0ful6VaLe2wxriVUsnAUGC5L8KI1ukQ6mLWpSNoaPJw9eur5OEccdhqGpq46vVVBDkVz18ynFCXrENiZV4Xt1IqEngPuFlrXbWffz9TKZWulEovKytry4zCC71jI3nswiGsK9ot+1WKw+LxaP70dgZby2r47/RhsgWZDXhV3EopF82lPVtr/f7+jtFaz9Jaj9Baj4iNjW3LjMJLJ6bFccuJfXl/TRFPL8g2HUfYxIPzsvhyQwl3np7GuNQY03GEF4IOdYBqHuh6CcjUWj/q+0jiSNxwQirbyvfwyPzNJEWHc9YQuR0hDuzNFfk8vyiHS8b05PLxyabjCC95c8U9HrgEOEEpldHycZqPc4lWUkrx73OPZlSvLvzl3bWsyqswHUlY1OItZdz54Xom9ovl7ilpcjPSRryZVfK91lpprQdprYe0fHzeHuFE64QEOXn+4uH0iArjytdWyWPx4jc2l1Rz7Rur6dM1kqemDSXIKc/i2Yl8t/xU54hgXp4xEo/WXP7qSnbXNpqOJCyirLqBy19ZSWiwk5dmjKRDqMt0JHGYpLj9WK+YCJ6/eDgFFbXMfD1dpgkK9jQ08YfX0tm5p4GXLhtBj6gw05FEK0hx+7nRKdH85/zBLM+t4MY319Dk9piOJAxpaHJz9RurWF+0m6emDWNQgmw/ZldS3AHgrCE9uGdKGl9tLOFvMsc7ILk9mlve+pHFW8p58NxBnJgWZzqSOAKHnA4o/MOM8b3YVdvIE99sISrcxe2nDZBZBAFCa82dH67ns3XbufP0AZw3PMF0JHGEpLgDyM2T+1BZu5cXFufSOSKYayfK4viB4OEvN/HminyuO743f5iQYjqOaANS3AFEKcXdU46isq6Rh+ZtIiosmOmjk0zHEj70wqIcnvl2K9NHJ/Hnk/qZjiPaiBR3gHE4FP85fzDV9U3c8eE6ghyKC0Ymmo4lfODl73O57/NMTh/UnXvPGihDY35Ebk4GIJfTwTMXDePYPrH89b21vLUy33Qk0cZe+j6Xf366kVMHduPxC2XrMX8jxR2gQl1Onr9kOBP7xXLre+uYu0LK21+8uDiHez/dyGlHd+PJaUNxyVORfke+owEs1OXkuYuHc3y/WG57fx1zlkt5292Li3P412eZnH50d56YKqXtr+S7GuBCXU6eu6S5vG//YB2zl+eZjiRa6YVF/1/aj08dIqXtx+Q7KwgJai7vE/p35Y4P1vPMt9nykI6NaK15+Musn29EPiGl7ffkuyuAlvK+eDhnDo7noXmbuPfTTDweKW+ra3J7uO29dfx34VamjUrkyamy0l8gkOmA4mfBQQ4ev3AI0ZHBvLwkl517Gnj4vMEEB0kRWFF9o5sb3lzD/I0l3HhCKn88sa9M+QsQUtziVxwOxV1npBHbIYSH5m1iV20jz140jIgQ+atiJbvrGrnyf+mszKvgH2cexWXjkk1HEu1ILqXEbyiluHZiKg+dO4jvt5Qx/YVllFbVm44lWhTuquXC55eypmAXT00bKqUdgKS4xQFdMDKRWZeMYEtpDWc+vYS1hZWmIwW8ldsqOOvpJRRV1vHKjFGcMSjedCRhgBS3OKjJaXG8d804nA7F+c8t5aOMItORAtbcFflMf2EZncJcfHjdeI7pIzuyByopbnFIA7p35OPrxzM4IYqb5mbw8JdZMuOkHTW5Pdzz8QZue38dY1Ki+eDa8fSOjTQdSxgkxS28Eh0Zwht/GM20UYn8d+FWZr6+it11so+lr+2saeDyV1fy6g/b+P0xvXhlxkg6hcsekYFOilt4LTjIwf1nH809U9L4dlMppz2xmNX5u0zH8ls/bC3n1CcWszy3gofOHcTfz0iTOdoCkOIWh0kpxYzxvXjn6rEoBec/t5Rnv90qQydtqMnt4dH5m7noxeVEhgbxwbXjZOld8StS3KJVhiZ15rMbJ3DKUd14cF4Wl72ygrLqBtOxbG/77jqmv7CcJ7/ZwrnDEvjk+mM4Kr6T6VjCYqS4Rat1CnPx9PSh3H/20azIreDUJxYzb/1207FsSWvNRxlFnPrEYtYX7+axCwfzn/MHy4NPYr+kuMURUUoxfXQSH19/DF07hHD1G6u5dvYqSqvlgR1vFVfW8fv/pXPT3AySoyP49IZjOHuobOgrDkz5YhW4ESNG6PT09Db/usLaGt0eZi3K4YlvthDmcvL3M9I4d1gPWT/jADwezZwV+TzwRRZuj+bPJ/djxrhk2a0mQCmlVmmtR3h1rBS3aGvZpTXc+t5aVuXt4ti+sdwzJY0UmXf8K5t2VHPXR+tZnlvB+NRo/n32IJKiw03HEgZJcQvjPB7N68vyeGheFg1NHi4Z25ObJvUhKjzYdDSjyqobeOzrzcxdkU9kSBB3nD6AC0Ykyk8lQopbWEdZdQOPzt/MWyvz6RDq4sZJfbhkTM+AWyq2vtHNy0tyeWbhVuob3Vw8pvl/ZJ0jAvt/ZOL/SXELy8naUcV9n2WyeEs5vWIiuOGEVKZGRgxvAAAHOUlEQVQMjvf7nVoamtx8sLqIpxZkU1RZx+QBcfzttP7yyLr4DSluYUlaa77dXMaDX2SRtaOahM5hXHVcb84fnkCoy2k6Xpuq3dvEmysKeGFRDjuq6jm6RyduO7U/41NlYSixf1LcwtK01izIKuXphdmsya8kJjKEP0zoxdSRibYfA99Z08Cc5fm8vCSXXbWNjEnpwrUTU5nQJ0bGscVBSXELW9Basyyngme+zWbxlnKCgxycOrAbF45IZExKNA6bTItzezTfZ5fz1sp85m8sodGtmdS/K9ce35vhPbuYjids4nCKWx7LEsYopRjbO5qxvaPZWFzFWyvz+WBNER9lFJPUJZwLRiQwZXA8PaMjTEfdr61lNXycUcy7qwopqqyjc7iLS8cmM3VkIn3iOpiOJ/yYV1fcSqlTgCcAJ/Ci1vqBgx0vV9yiteob3cxbv4O5K/NZllMBQJ+ukUwaEMeJaV0ZktjZ2AMqTW4Pq/J28XVmCV9nlpJbvgeACX1iuHBkIiemxRES5F9j9aL9tOlQiVLKCWwGTgQKgZXANK31xgP9Hilu0RYKKmqZv7GErzNLWJFbQZNHEx0RzOiULgxJjGJoUmcGxnciLNg3ZbmnoYl1RbtZk19JRsEuludWUFnbiMupGJMSzYlpcUwaEEePqDCfvL8ILG09VDIKyNZa57R88bnAWcABi1uItpDYJZwrjunFFcf0YnddI99tLmNBZgmr8nfx+bodADgdiv7dOtA3rgOJXcJJ7BxGYpdwkrqE0yUimJAgxwFvCmqtaWjyUF7TQEFFHQUVtRTsqqWgopasHdVsLqnmp9Vqe0aHc0L/rkweEMeEPjF0CJXNDIQ53hR3D6DgF58XAqN9E0eI/esU5uLMwfGcObh5c9zymgYy8ivJKGj+WJFbwYcZRez7A6RDQXhwEGHBTsKDnWgNtXvd1O1toq7Rzb7LiDsUdO8URkpsBCelxTE0qTODE6PoIg/KCAvxprj3d7nym/EVpdRMYCZAUlLSEcYS4uBiIkOYnBbH5LS4n1/b2+ShuLKOgl215FfUUlnbSN1eN7V73dTubaJ2rxulIDzYSZgrqPmfwU66RAST2Ln5Kr17VKjfPxQk7M+b4i4Efrn9RgJQvO9BWutZwCxoHuNuk3RCHIbgIAfJMREkx1hzFooQbcWbS4uVQB+lVC+lVDAwFfjYt7GEEEIcyCGvuLXWTUqp64EvaZ4O+LLWeoPPkwkhhNgvrx7A0Vp/Dnzu4yxCCCG8IHdhhBDCZqS4hRDCZqS4hRDCZqS4hRDCZqS4hRDCZnyyHrdSqgzIa+VvjwHK2zCOSf5yLv5yHiDnYkX+ch5wZOfSU2sd682BPinuI6GUSvd2hSyr85dz8ZfzADkXK/KX84D2OxcZKhFCCJuR4hZCCJuxYnHPMh2gDfnLufjLeYCcixX5y3lAO52L5ca4hRBCHJwVr7iFEEIchCWLWyl1r1JqrVIqQyn1lVIq3nSm1lBKPayUymo5lw+UUlGmM7WWUup8pdQGpZRHKWW7GQBKqVOUUpuUUtlKqdtM5zkSSqmXlVKlSqn1prMcCaVUolJqoVIqs+Xv1k2mM7WWUipUKbVCKfVjy7n8w6fvZ8WhEqVUR611VcuvbwTStNZXG4512JRSJwELWpbGfRBAa32r4VitopQaAHiA54E/a61tsxt0aza8tjKl1LFADfCa1nqg6TytpZTqDnTXWq9WSnUAVgG/s+P3RTVvbBqhta5RSrmA74GbtNbLfPF+lrzi/qm0W0Swn63S7EBr/ZXWuqnl02U07x5kS1rrTK31JtM5WunnDa+11nuBnza8tiWt9SKgwnSOI6W13q61Xt3y62ogk+Y9bm1HN6tp+dTV8uGz3rJkcQMope5TShUAFwF3mc7TBq4AvjAdIkDtb8NrWxaEv1JKJQNDgeVmk7SeUsqplMoASoH5WmufnYux4lZKfa2UWr+fj7MAtNZ3aK0TgdnA9aZyHsqhzqPlmDuAJprPxbK8OReb8mrDa2GGUioSeA+4eZ+ftm1Fa+3WWg+h+SfrUUopnw1jebUDji9orSd7eegc4DPgbh/GabVDnYdS6jLgDGCStuINhV84jO+J3Xi14bVofy3jwe8Bs7XW75vO0xa01pVKqW+BUwCf3EC25FCJUqrPLz49E8gyleVIKKVOAW4FztRa15rOE8Bkw2sLarmh9xKQqbV+1HSeI6GUiv1p1phSKgyYjA97y6qzSt4D+tE8iyEPuFprXWQ21eFTSmUDIcDOlpeW2XF2DIBS6mzgKSAWqAQytNYnm03lPaXUacDj/P+G1/cZjtRqSqk3gYk0r0RXAtyttX7JaKhWUEodAywG1tH83zrA7S173NqKUmoQ8D+a/345gLe11v/02ftZsbiFEEIcmCWHSoQQQhyYFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtiMFLcQQtjM/wGi0xonU1UbyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=np.arange(-3,3.01,0.1)\n",
    "y=x**2\n",
    "plt.plot(x,y)\n",
    "plt.plot(2,4,'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**答案**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "x=Variable(torch.FloatTensor([2]),requires_grad=True)\n",
    "y=x**2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
